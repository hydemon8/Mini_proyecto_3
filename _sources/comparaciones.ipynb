{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef54fcc0",
   "metadata": {},
   "source": [
    "# **Comparaciones y Conclusiones**\n",
    "\n",
    "## Modelos Implementados y Resultados\n",
    "\n",
    "| Modelo                      | Accuracy    | F1-Score Weighted | F1-Score Macro | ROC-AUC Macro | Observaciones                                                                          |\n",
    "| --------------------------- | ----------- | ----------------- | -------------- | ------------- | -------------------------------------------------------------------------------------- |\n",
    "| **DistilBERT**              | **91.02 %** | **90.94 %**       | 90.73 %        | **99.17 %**   | Mejor desempeño global, balanceado entre clases, excelente separación probabilística.  |\n",
    "| **Word2Vec + BiLSTM**       | 73.82 %     | 73.42 %           | 72.98 %        | 95.86 %       | Buen discriminador, pero sobreajuste y debilidad en clases con solapamiento semántico. |\n",
    "| **CNN-1D (con GloVe)**      | 87.78 %     | 87.70 %           | 87.50 %        | 98.84 %       | Muy sólido, generaliza bien, errores concentrados en pocas clases ambiguas.            |\n",
    "| **TF-IDF + XGBoost (GPU)**  | 73.82 %     | 73.62 %           | 73.03 %        | 97.05 %       | Rendimiento competitivo, robusto en alta dimensionalidad, leve sobreajuste.            |\n",
    "| **FastText (preentrenado)** | 68.33 %     | 68.23 %           | 68.10 %        | 95.72 %       | Más eficiente pero el peor en efectividad; confunde clases con vocabulario similar.    |\n",
    "\n",
    "## Comparaciones y Análisis Crítico\n",
    "\n",
    "El análisis comparativo de los cinco modelos implementados evidencia diferencias claras en cuanto a **capacidad de generalización, eficiencia y robustez**:\n",
    "\n",
    "* **DistilBERT** se posiciona como el modelo con mejor rendimiento global, alcanzando un **F1-Score Weighted de 90.94 %** y un **ROC-AUC Macro de 99.17 %**.\n",
    "\n",
    "  * **Razones de su éxito:** la arquitectura basada en *Transformers* permite capturar relaciones contextuales profundas en los textos, mientras que el uso de **pérdida ponderada** y *fine-tuning* específico sobre el corpus asegura un aprendizaje equilibrado entre clases.\n",
    "  * **Limitaciones:** alto costo computacional y riesgo de sobreajuste, evidenciado por la divergencia entre *Training Loss* y *Validation Loss* en etapas avanzadas.\n",
    "\n",
    "* **CNN-1D con GloVe** mostró un desempeño competitivo (**F1-Score Weighted ≈ 87.7 %**) con menor complejidad y tiempos de entrenamiento más reducidos.\n",
    "\n",
    "  * **Fortalezas:** buena capacidad para detectar patrones locales en los textos y generalización estable.\n",
    "  * **Limitaciones:** menor sensibilidad a dependencias largas entre palabras, lo que restringe su capacidad frente a contextos más complejos.\n",
    "\n",
    "* **BiLSTM con Word2Vec** y **XGBoost con TF-IDF** se ubicaron en un rango intermedio (**≈ 73 % F1 ponderado**).\n",
    "\n",
    "  * **Razones:** aunque capturan secuencias o aprovechan representaciones dispersas, su rendimiento se ve limitado por la falta de representaciones contextuales dinámicas.\n",
    "  * **Limitaciones:** mayor vulnerabilidad a confusiones semánticas y sobreajuste en clases minoritarias.\n",
    "\n",
    "* **FastText** fue el modelo más ligero, pero también el menos preciso (**≈ 68 % F1 ponderado**).\n",
    "\n",
    "  * **Fortalezas:** eficiencia y rapidez en entrenamiento.\n",
    "  * **Limitaciones:** incapacidad para diferenciar adecuadamente entre categorías con vocabulario similar, lo que reduce su aplicabilidad en escenarios de alta exigencia.\n",
    "\n",
    "## Análisis Transversal e Interpretabilidad\n",
    "\n",
    "Más allá de las métricas cuantitativas, se observa que el rendimiento de los modelos depende estrechamente de la **naturaleza y estructura lingüística del corpus**.\n",
    "Los modelos con embeddings **contextuales** (como DistilBERT) mostraron una clara ventaja al manejar ambigüedad léxica, mientras que los modelos con embeddings **estáticos** (Word2Vec, GloVe, FastText) dependen fuertemente del vocabulario y de la calidad del preprocesamiento.\n",
    "\n",
    "Una futura línea de mejora consistiría en aplicar herramientas de **interpretabilidad de modelos** (como *LIME* o *SHAP*) para identificar qué palabras o secuencias son más determinantes en las predicciones. Esto permitiría comprender mejor las decisiones del modelo, detectar posibles sesgos y fortalecer la transparencia del sistema.\n",
    "\n",
    "## Eficiencia Computacional y Escalabilidad\n",
    "\n",
    "Desde una perspectiva práctica, el análisis comparativo también revela una diferencia notable en **coste-beneficio** entre modelos:\n",
    "\n",
    "* **DistilBERT** ofrece la mayor precisión, pero con un **costo computacional elevado** (≈10× mayor que CNN-1D).\n",
    "* **CNN-1D y XGBoost** representan opciones **más ligeras y eficientes**, con métricas competitivas y tiempos de inferencia mucho menores.\n",
    "\n",
    "Esto sugiere la conveniencia de adoptar **estrategias híbridas o jerárquicas**, donde un modelo ligero realice una clasificación preliminar y un modelo más complejo (como DistilBERT) refine las predicciones en las instancias más ambiguas o críticas.\n",
    "\n",
    "## Conclusiones Críticas\n",
    "\n",
    "1. **Mejor modelo:** DistilBERT es el más adecuado para entornos de producción donde se prioriza la precisión y la robustez.\n",
    "2. **Éxito técnico:** el uso de embeddings contextuales y la optimización mediante pérdida ponderada fueron los principales factores diferenciadores frente a los modelos clásicos.\n",
    "3. **Limitaciones generales:** los modelos más complejos exigen más recursos y presentan riesgo de sobreajuste, mientras que los más simples, aunque eficientes, sacrifican capacidad contextual.\n",
    "4. **Recomendaciones de mejora:**\n",
    "\n",
    "   * Aplicar **regularización avanzada** (*dropout dinámico*, *layer freezing*) para mitigar el sobreajuste en Transformers.\n",
    "   * Desarrollar **ensembles híbridos** (por ejemplo, CNN-1D + DistilBERT) que integren las ventajas de ambos enfoques.\n",
    "   * Evaluar **métricas complementarias** como el *Matthews Correlation Coefficient (MCC)* o la *Cohen’s Kappa* para un análisis más robusto en clases desbalanceadas.\n",
    "   * Implementar **model compression** (distillation o quantization) para reducir el tamaño y costo de inferencia de modelos grandes sin pérdida significativa de rendimiento.\n",
    "\n",
    "## Perspectiva Futura\n",
    "\n",
    "De cara a próximas etapas del proyecto, se proponen las siguientes líneas de investigación y mejora:\n",
    "\n",
    "* **Aprendizaje continuo:** explorar *continual fine-tuning* para adaptar DistilBERT a nuevos dominios sin degradar su rendimiento previo.\n",
    "* **Modelos multilingües:** evaluar alternativas como *mBERT* o *XLM-RoBERTa* que amplíen la aplicabilidad a textos en otros idiomas.\n",
    "* **Análisis de sesgos y errores:** desarrollar un sistema automatizado de diagnóstico de errores para ajustar dinámicamente los pesos de clase.\n",
    "* **Arquitecturas jerárquicas de atención:** incorporar modelos con atención jerárquica (*Hierarchical Attention Networks* o *HiBERT*) que capturen la estructura semántica y discursiva de los textos.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
