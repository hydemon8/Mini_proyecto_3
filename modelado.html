

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Modelado &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modelado';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Comparaciones y Conclusiones" href="comparaciones.html" />
    <link rel="prev" title="Análisis exploratorio de Datos" href="eda.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="eda.html"><strong>Análisis exploratorio de Datos</strong></a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Modelado</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="comparaciones.html"><strong>Comparaciones y Conclusiones</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmodelado.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/modelado.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelado</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion">Métricas de Evaluación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proceso-documentado">Proceso Documentado</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-1-distilbert">Modelo 1: DistilBERT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-rendimiento-en-el-conjunto-de-prueba">Métricas de rendimiento en el conjunto de prueba</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-errores">Análisis de errores</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-2-word2vec-bilstm">Modelo 2: Word2Vec + BiLSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-3-cnn-1d-para-texto-con-embeddings-preentrenados">Modelo 3: CNN-1D para texto (con embeddings preentrenados)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Métricas de rendimiento en el conjunto de prueba</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-4-tf-idf-xgboost-gpu-version">Modelo 4: TF-IDF + XGBoost (GPU version)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Análisis de errores</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-5-fasttext">Modelo 5: FastText</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modelado">
<h1><strong>Modelado</strong><a class="headerlink" href="#modelado" title="Permalink to this heading">#</a></h1>
<p>En este apartado se implementan los modelos de clasificación descritos en el proyecto sobre el conjunto de currículums previamente procesado. Cada modelo se entrena, evalúa y compara utilizando métricas estándar para clasificación multiclase.</p>
<section id="metricas-de-evaluacion">
<h2>Métricas de Evaluación<a class="headerlink" href="#metricas-de-evaluacion" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Exactitud (Accuracy):</strong> proporción de predicciones correctas sobre el total de ejemplos.</p></li>
<li><p><strong>Precisión (Precision):</strong> proporción de verdaderos positivos sobre el total de predicciones positivas.</p></li>
<li><p><strong>Exhaustividad (Recall):</strong> proporción de verdaderos positivos detectados sobre el total de positivos reales.</p></li>
<li><p><strong>F1-Score:</strong> media armónica entre precisión y recall, útil para evaluar el balance entre ambos.</p></li>
<li><p><strong>Matriz de Confusión:</strong> visualiza aciertos y errores por clase, identificando patrones de confusión.</p></li>
<li><p><strong>ROC-AUC (cuando aplica):</strong> evalúa la capacidad discriminativa del modelo en escenarios multiclase.</p></li>
</ul>
</section>
<section id="proceso-documentado">
<h2>Proceso Documentado<a class="headerlink" href="#proceso-documentado" title="Permalink to this heading">#</a></h2>
<p>A lo largo del notebook se documenta el flujo completo de cada modelo, incluyendo:</p>
<ol class="arabic simple">
<li><p>Entrenamiento y ajuste de hiperparámetros.</p></li>
<li><p>Evaluación mediante las métricas descritas.</p></li>
</ol>
<p>Para todos los modelos evaluados, el <strong>F1-Score Weighted</strong> se establece como la <strong>métrica de rendimiento principal</strong> y <strong>criterio de optimización</strong>. Pues si bien el desbalance de clases fue corregido mediante <strong>data augmentation</strong>, el F1-Score Weighted sigue siendo la métrica más adecuada para evaluar el rendimiento global. Esto se debe a que pondera la contribución de cada clase según su frecuencia efectiva, ofreciendo una evaluación más estable ante posibles variaciones en la distribución de datos entre los conjuntos de entrenamiento, validación y prueba.  A diferencia de la <strong>Accuracy</strong> (susceptible al sesgo hacia clases más frecuentes) y del F1-Score Macro (que otorga el mismo peso a todas las clases, independientemente de su soporte), el F1-Score Weighted proporciona una medida más equilibrada y representativa del desempeño del modelo en el dataset completo.</p>
<p>El análisis inicia con <strong>modelos basados en Transformers</strong> y continúa con <strong>arquitecturas clásicas y ligeras</strong>, permitiendo comparar desempeño y eficiencia entre enfoques.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span>
    <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span>
    <span class="n">auc</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">label_binarize</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| hide-cell</span>

<span class="n">category_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;ACCOUNTANT&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;ADVOCATE&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;AGRICULTURE&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;APPAREL&#39;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;ARTS&#39;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;AUTOMOBILE&#39;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s1">&#39;AVIATION&#39;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s1">&#39;BANKING&#39;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;BPO&#39;</span><span class="p">,</span>
    <span class="mi">9</span><span class="p">:</span> <span class="s1">&#39;BUSINESS-DEVELOPMENT&#39;</span><span class="p">,</span>
    <span class="mi">10</span><span class="p">:</span> <span class="s1">&#39;CHEF&#39;</span><span class="p">,</span>
    <span class="mi">11</span><span class="p">:</span> <span class="s1">&#39;CONSTRUCTION&#39;</span><span class="p">,</span>
    <span class="mi">12</span><span class="p">:</span> <span class="s1">&#39;CONSULTANT&#39;</span><span class="p">,</span>
    <span class="mi">13</span><span class="p">:</span> <span class="s1">&#39;DESIGNER&#39;</span><span class="p">,</span>
    <span class="mi">14</span><span class="p">:</span> <span class="s1">&#39;DIGITAL-MEDIA&#39;</span><span class="p">,</span>
    <span class="mi">15</span><span class="p">:</span> <span class="s1">&#39;ENGINEERING&#39;</span><span class="p">,</span>
    <span class="mi">16</span><span class="p">:</span> <span class="s1">&#39;FINANCE&#39;</span><span class="p">,</span>
    <span class="mi">17</span><span class="p">:</span> <span class="s1">&#39;FITNESS&#39;</span><span class="p">,</span>
    <span class="mi">18</span><span class="p">:</span> <span class="s1">&#39;HEALTHCARE&#39;</span><span class="p">,</span>
    <span class="mi">19</span><span class="p">:</span> <span class="s1">&#39;HR&#39;</span><span class="p">,</span>
    <span class="mi">20</span><span class="p">:</span> <span class="s1">&#39;INFORMATION-TECHNOLOGY&#39;</span><span class="p">,</span>
    <span class="mi">21</span><span class="p">:</span> <span class="s1">&#39;PUBLIC-RELATIONS&#39;</span><span class="p">,</span>
    <span class="mi">22</span><span class="p">:</span> <span class="s1">&#39;SALES&#39;</span><span class="p">,</span>
    <span class="mi">23</span><span class="p">:</span> <span class="s1">&#39;TEACHER&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mostrar_matriz_confusion</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">category_map</span><span class="p">,</span> <span class="n">titulo</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Genera una matriz de confusión con paleta morada personalizada.&quot;&quot;&quot;</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">category_map</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y_true</span><span class="p">)))]</span>

    <span class="c1"># Paleta morada integrada</span>
    <span class="n">palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">blend_palette</span><span class="p">([</span><span class="s2">&quot;#D5C7EF&quot;</span><span class="p">,</span> <span class="s2">&quot;#9c69c2&quot;</span><span class="p">],</span> <span class="n">n_colors</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
        <span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">palette</span><span class="p">,</span>
        <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Cantidad&#39;</span><span class="p">},</span>
        <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span>
        <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_names</span><span class="p">,</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_names</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicho&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdadero&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">titulo</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mostrar_curvas_roc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">titulo</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dibuja curvas ROC por clase.&quot;&quot;&quot;</span>
    <span class="n">y_true_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true_bin</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_prob</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Clase </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="w"> </span><span class="n">tpr</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;FPR&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;TPR&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">titulo</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">analizar_errores</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">category_map</span><span class="p">,</span> <span class="n">nombre_modelo</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Imprime análisis de errores global y por clase.&quot;&quot;&quot;</span>
    <span class="n">errores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; RESUMEN DE ERRORES - </span><span class="si">{</span><span class="n">nombre_modelo</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predicciones correctas: </span><span class="si">{</span><span class="n">total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">errores</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Predicciones incorrectas: </span><span class="si">{</span><span class="n">errores</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Total de ejemplos: </span><span class="si">{</span><span class="n">total</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Accuracy: </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">errores</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Tasa de error: </span><span class="si">{</span><span class="p">(</span><span class="n">errores</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> ERRORES POR CLASE:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">clase</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_true</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">==</span> <span class="n">clase</span>
        <span class="n">total_clase</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">errores_clase</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="n">clase</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">!=</span> <span class="n">clase</span><span class="p">))</span>
        <span class="n">accuracy_clase</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_clase</span> <span class="o">-</span> <span class="n">errores_clase</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_clase</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">category_map</span><span class="p">[</span><span class="n">clase</span><span class="p">]</span><span class="si">:</span><span class="s2">25s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">errores_clase</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total_clase</span><span class="si">}</span><span class="s2"> errores &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">accuracy_clase</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% accuracy)&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> CONFUSIONES MÁS COMUNES:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">confusiones</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">confusiones</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">confusiones</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">top_conf</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">confusiones</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">top_conf</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">category_map</span><span class="p">[</span><span class="n">true</span><span class="p">]</span><span class="si">}</span><span class="s2"> → </span><span class="si">{</span><span class="n">category_map</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> veces (</span><span class="si">{</span><span class="n">count</span><span class="o">/</span><span class="n">errores</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">% de errores)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">graficar_historial_entrenamiento</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">results_dir</span><span class="p">,</span> <span class="n">nombre_modelo</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Genera gráficas de pérdida y métricas de entrenamiento/validación.&quot;&quot;&quot;</span>
    <span class="n">color_train</span> <span class="o">=</span> <span class="s2">&quot;#9c69c2&quot;</span>
    <span class="n">color_val</span> <span class="o">=</span> <span class="s2">&quot;#D5C7EF&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Generando gráficas de entrenamiento para </span><span class="si">{</span><span class="n">nombre_modelo</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

    <span class="c1"># Pérdida</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

    <span class="c1"># Métrica F1 Weighted</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train F1 (Weighted)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation F1 (Weighted)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model F1-Score (Weighted)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">path_save</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">nombre_modelo</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_training_history.png&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path_save</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Gráficas guardadas en: </span><span class="si">{</span><span class="n">path_save</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">graficar_historial_xgboost</span><span class="p">(</span><span class="n">df_history</span><span class="p">,</span> <span class="n">results_dir</span><span class="p">,</span> <span class="n">nombre_modelo</span><span class="p">):</span>


    <span class="n">color_train</span> <span class="o">=</span> <span class="s2">&quot;#9c69c2&quot;</span>
    <span class="n">color_val</span> <span class="o">=</span> <span class="s2">&quot;#D5C7EF&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Generando gráficas de entrenamiento para </span><span class="si">{</span><span class="n">nombre_modelo</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

    <span class="c1"># --- Pérdida ---</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Epoch&#39;</span><span class="p">],</span> <span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Epoch&#39;</span><span class="p">],</span> <span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

    <span class="c1"># --- F1 Weighted ---</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Epoch&#39;</span><span class="p">],</span> <span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Train F1 Weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train F1 (Weighted)&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Epoch&#39;</span><span class="p">],</span> <span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;Val F1 Weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation F1 (Weighted)&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model F1-Score (Weighted)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">path_save</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">nombre_modelo</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">_training_history.png&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path_save</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Gráficas guardadas en: </span><span class="si">{</span><span class="n">path_save</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>La métrica personalizada <strong><code class="docutils literal notranslate"><span class="pre">F1WeightedScore</span></code></strong> fue implementada en TensorFlow/Keras con el objetivo de calcular el <strong>F1-Score ponderado</strong> durante el entrenamiento y evaluación de modelos de clasificación multiclase. Esta clase extiende <code class="docutils literal notranslate"><span class="pre">tf.keras.metrics.Metric</span></code> y mantiene una <strong>matriz de confusión acumulada</strong> como variable de estado, actualizada en cada batch con las predicciones y etiquetas verdaderas. A partir de dicha matriz se derivan los valores de <strong>verdaderos positivos (TP), falsos positivos (FP) y falsos negativos (FN)</strong> por clase, con los que se calculan precisión y recall, y posteriormente el F1 por clase. El resultado final se pondera según el <strong>soporte (número de ejemplos por clase)</strong>, produciendo un F1 global que refleja el rendimiento del modelo considerando el desbalance de clases. Esta métrica se diseñó para complementar las métricas estándar de Keras y proporcionar un criterio más representativo en escenarios multiclase con distribución desigual.</p>
<div class="math notranslate nohighlight">
\[
F1_{weighted} = \frac{\sum_{i=1}^{C} \; \frac{2 \cdot TP_i}{2 \cdot TP_i + FP_i + FN_i} \cdot n_i}{\sum_{i=1}^{C} n_i}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p>(C) = número total de clases</p></li>
<li><p>(TP_i) = verdaderos positivos de la clase (i)</p></li>
<li><p>(FP_i) = falsos positivos de la clase (i)</p></li>
<li><p>(FN_i) = falsos negativos de la clase (i)</p></li>
<li><p>(n_i) = soporte de la clase (i) (número de ejemplos reales en esa clase)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="k">class</span><span class="w"> </span><span class="nc">F1WeightedScore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;f1_weighted&quot;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">F1WeightedScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_classes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Debes proporcionar &#39;num_classes&#39;.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cm&#39;</span><span class="p">,</span> 
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span> 
            <span class="n">initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> 
            <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">y_pred_classes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_true_classes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">batch_cm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">y_true_classes</span><span class="p">,</span>
            <span class="n">predictions</span><span class="o">=</span><span class="n">y_pred_classes</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">batch_cm</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">result</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">TP</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="p">)</span>
        <span class="n">FP</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">TP</span>  
        <span class="n">FN</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">TP</span>  
        
        <span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
        <span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
        <span class="n">f1_score_per_class</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
        
        <span class="n">support</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total_support</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">support</span><span class="p">)</span>
        
        <span class="n">weighted_f1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">f1_score_per_class</span> <span class="o">*</span> <span class="n">support</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">total_support</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="n">weighted_f1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cm</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-1-distilbert">
<h2>Modelo 1: DistilBERT<a class="headerlink" href="#modelo-1-distilbert" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">EarlyStoppingCallback</span><span class="p">,</span> <span class="n">TrainerCallback</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils.class_weight</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_class_weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/davzz/miniconda3/envs/torch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<p>Para este modelo se utilizó DistilBERT-base-uncased, descargado previamente desde Hugging Face y almacenado localmente en MODEL_PATH. Esto permite cargar el modelo sin conexión y acelerar el proceso de entrenamiento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;distilbert-base-uncased&quot;</span>
<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="s2">&quot;modelos/distilbert-base-uncased&quot;</span>
<span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="s2">&quot;./results_distilbert&quot;</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">24</span>  
</pre></div>
</div>
</div>
</div>
<p>Los datasets de entrenamiento, validación y prueba se cargan desde archivos <code class="docutils literal notranslate"><span class="pre">.npz</span></code> que contienen <code class="docutils literal notranslate"><span class="pre">input_ids</span></code>, <code class="docutils literal notranslate"><span class="pre">attention_mask</span></code> y <code class="docutils literal notranslate"><span class="pre">labels</span></code>. Estos tensores se convierten en objetos <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> de Hugging Face, facilitando su integración con el <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> para entrenamiento y evaluación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Carga de Datos Tokenizados</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_data</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">],</span>
        <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">],</span>
        <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
    <span class="p">}</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;processed_data/distilbert_train.npz&#39;</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;processed_data/distilbert_val.npz&#39;</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;processed_data/distilbert_test.npz&#39;</span><span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>
<span class="n">test_dataset_hf</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Se instancia <code class="docutils literal notranslate"><span class="pre">AutoModelForSequenceClassification</span></code> desde la ruta local, indicando el número de clases. El modelo se ubica automáticamente en el dispositivo disponible (<code class="docutils literal notranslate"><span class="pre">device_map=&quot;auto&quot;</span></code>). Se carga también el tokenizer correspondiente para asegurar la compatibilidad de los textos con el modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Cargar modelo local</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">MODEL_PATH</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span>
    <span class="n">use_safetensors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span> 
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Modelo local cargado correctamente.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Dispositivo: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>`torch_dtype` is deprecated! Use `dtype` instead!
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at modelos/distilbert-base-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;, &#39;pre_classifier.bias&#39;, &#39;pre_classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Modelo local cargado correctamente.
 Dispositivo: cuda:0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Función de Métricas</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">predictions</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Predicciones inválidas o vacías.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;f1_weighted&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;f1_macro&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;precision_weighted&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;recall_weighted&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s1">&#39;roc_auc_macro&#39;</span><span class="p">:</span> <span class="mf">0.0</span>
        <span class="p">}</span>

    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">label_ids</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span>
        <span class="s1">&#39;f1_weighted&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;f1_macro&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;precision_weighted&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;recall_weighted&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;roc_auc_macro&#39;</span><span class="p">:</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Callback para capturar métricas de TRAIN</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TrainMetricsCallback</span><span class="p">(</span><span class="n">TrainerCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback para calcular métricas en el conjunto de entrenamiento al final de cada epoch&quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics_history</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Evaluar en el conjunto de entrenamiento</span>
        <span class="n">train_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">train_output</span><span class="p">)</span>
        
        <span class="c1"># Agregar el epoch actual</span>
        <span class="n">train_metrics</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">epoch</span>
        <span class="n">train_metrics</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">log_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
<p>Se utilizó un <strong><code class="docutils literal notranslate"><span class="pre">WeightedTrainer</span></code></strong> personalizado, que extiende la clase estándar <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> de <strong>Hugging Face</strong>.<br />
Este <em>wrapper</em> ajusta la función de pérdida interna de <strong>Cross-Entropy</strong> (<code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code>) mediante la inclusión de un vector de pesos <strong>W</strong>:</p>
<p>Formalmente, la función de pérdida optimizada en cada paso de entrenamiento es:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(x, y) = \text{CrossEntropyLoss}(x, y, \text{weight}=W)
\]</div>
<p>Esto garantiza que los errores de predicción en las clases con menor frecuencia efectiva reciban una penalización significativamente mayor,<br />
obligando al modelo a aprender patrones robustos en categorías subrepresentadas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5. Pesos de Clase Balanceados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Calculando pesos de clase...&quot;</span><span class="p">)</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="n">compute_class_weight</span><span class="p">(</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span>
<span class="n">weights_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">class_weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">WeightedTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_items_in_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>
        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights_tensor</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Calculando pesos de clase...
</pre></div>
</div>
</div>
</div>
<p>El entrenamiento se configuró para optimizar la generalización y manejar el desbalance de clases, con <strong>8 épocas</strong>, <strong>batch size de 16/32</strong> (entrenamiento/evaluación), y una <strong>tasa de aprendizaje de 3e-5</strong> con <strong>500 pasos de calentamiento</strong>. Se aplica <strong>weight decay de 0.01</strong>, evaluaciones y checkpoints al final de cada época, activando <strong><code class="docutils literal notranslate"><span class="pre">load_best_model_at_end</span></code></strong> para conservar el modelo con mejor <strong>F1 ponderado</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 6. Argumentos de Entrenamiento</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">OUTPUT_DIR</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">logging_dir</span><span class="o">=</span><span class="s1">&#39;./logs_distilbert&#39;</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>   
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>         
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&quot;f1_weighted&quot;</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>                    
    <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
<span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<p>Se inicializa el <code class="docutils literal notranslate"><span class="pre">WeightedTrainer</span></code> con el modelo, los datasets, el tokenizer, la función de métricas y un callback de <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> que detiene el entrenamiento si no hay mejora en dos épocas consecutivas. El entrenamiento se lanza con <code class="docutils literal notranslate"><span class="pre">trainer.train()</span></code>, iniciando el fine-tuning de DistilBERT sobre el corpus específico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 7. Inicializar Trainer con Callback</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">WeightedTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)]</span>
<span class="p">)</span>

<span class="c1"># Agregar callback para métricas de train</span>
<span class="n">train_metrics_callback</span> <span class="o">=</span> <span class="n">TrainMetricsCallback</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="n">train_metrics_callback</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🚀 INICIANDO FINE-TUNING DE DISTILBERT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ Entrenamiento completado!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_48107/317751910.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.
  trainer = WeightedTrainer(
The model is already on multiple devices. Skipping the move to device specified in `args`.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
🚀 INICIANDO FINE-TUNING DE DISTILBERT
======================================================================
</pre></div>
</div>
<div class="output text_html">
    <div>
      
      <progress value='1872' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1872/2340 11:30 < 02:52, 2.71 it/s, Epoch 16/20]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Accuracy</th>
      <th>F1 Weighted</th>
      <th>F1 Macro</th>
      <th>Precision Weighted</th>
      <th>Recall Weighted</th>
      <th>Roc Auc Macro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>3.174600</td>
      <td>3.156494</td>
      <td>0.077307</td>
      <td>0.035539</td>
      <td>0.033695</td>
      <td>0.037370</td>
      <td>0.077307</td>
      <td>0.736668</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.034500</td>
      <td>2.621757</td>
      <td>0.518703</td>
      <td>0.460926</td>
      <td>0.460242</td>
      <td>0.546053</td>
      <td>0.518703</td>
      <td>0.915934</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.868400</td>
      <td>1.509014</td>
      <td>0.790524</td>
      <td>0.762421</td>
      <td>0.753044</td>
      <td>0.810530</td>
      <td>0.790524</td>
      <td>0.968110</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.040400</td>
      <td>0.799623</td>
      <td>0.855362</td>
      <td>0.851806</td>
      <td>0.845947</td>
      <td>0.856420</td>
      <td>0.855362</td>
      <td>0.981524</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.641700</td>
      <td>0.628869</td>
      <td>0.862843</td>
      <td>0.858072</td>
      <td>0.852563</td>
      <td>0.864235</td>
      <td>0.862843</td>
      <td>0.984948</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.423300</td>
      <td>0.575531</td>
      <td>0.872818</td>
      <td>0.868424</td>
      <td>0.864090</td>
      <td>0.876264</td>
      <td>0.872818</td>
      <td>0.982535</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.299500</td>
      <td>0.584471</td>
      <td>0.880299</td>
      <td>0.876548</td>
      <td>0.871866</td>
      <td>0.891924</td>
      <td>0.880299</td>
      <td>0.981208</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.206800</td>
      <td>0.576350</td>
      <td>0.885287</td>
      <td>0.881846</td>
      <td>0.877137</td>
      <td>0.892063</td>
      <td>0.885287</td>
      <td>0.984544</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.147000</td>
      <td>0.673555</td>
      <td>0.870324</td>
      <td>0.866095</td>
      <td>0.861634</td>
      <td>0.872288</td>
      <td>0.870324</td>
      <td>0.982403</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.117000</td>
      <td>0.602490</td>
      <td>0.885287</td>
      <td>0.881073</td>
      <td>0.876284</td>
      <td>0.885406</td>
      <td>0.885287</td>
      <td>0.982708</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.066300</td>
      <td>0.614953</td>
      <td>0.892768</td>
      <td>0.891403</td>
      <td>0.886476</td>
      <td>0.895985</td>
      <td>0.892768</td>
      <td>0.981317</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.049100</td>
      <td>0.676165</td>
      <td>0.887781</td>
      <td>0.884054</td>
      <td>0.879278</td>
      <td>0.890961</td>
      <td>0.887781</td>
      <td>0.980870</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.032500</td>
      <td>0.662613</td>
      <td>0.885287</td>
      <td>0.882795</td>
      <td>0.877941</td>
      <td>0.886930</td>
      <td>0.885287</td>
      <td>0.983875</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.012500</td>
      <td>0.697023</td>
      <td>0.880299</td>
      <td>0.878090</td>
      <td>0.873019</td>
      <td>0.882469</td>
      <td>0.880299</td>
      <td>0.983363</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.031700</td>
      <td>0.682754</td>
      <td>0.880299</td>
      <td>0.878277</td>
      <td>0.872982</td>
      <td>0.883029</td>
      <td>0.880299</td>
      <td>0.983510</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.015000</td>
      <td>0.692888</td>
      <td>0.887781</td>
      <td>0.885793</td>
      <td>0.881070</td>
      <td>0.894894</td>
      <td>0.887781</td>
      <td>0.983058</td>
    </tr>
  </tbody>
</table><p></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>✓ Entrenamiento completado!
</pre></div>
</div>
</div>
</div>
<p>Una vez entrenado, el modelo se evalúa sobre el conjunto de prueba. Se obtienen las predicciones (<code class="docutils literal notranslate"><span class="pre">preds</span></code>), las etiquetas verdaderas (<code class="docutils literal notranslate"><span class="pre">labels</span></code>) y los textos originales (<code class="docutils literal notranslate"><span class="pre">test_texts</span></code>). Se calculan nuevamente las métricas de rendimiento con compute_metrics, y se imprime un resumen detallado de los resultados finales.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;📊 GENERANDO VISUALIZACIONES DEL ENTRENAMIENTO&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="c1"># Extraer historial del trainer (validación)</span>
<span class="n">log_history</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">log_history</span>

<span class="c1"># Inicializar diccionario de historial</span>
<span class="n">history_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;f1_weighted&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="c1"># Extraer métricas de TRAIN del callback</span>
<span class="n">train_metrics</span> <span class="o">=</span> <span class="n">train_metrics_callback</span><span class="o">.</span><span class="n">train_metrics_history</span>
<span class="k">for</span> <span class="n">tm</span> <span class="ow">in</span> <span class="n">train_metrics</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tm</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tm</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
    <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tm</span><span class="p">[</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">])</span>

<span class="c1"># Extraer métricas de VALIDACIÓN del log_history</span>
<span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">log_history</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;eval_loss&#39;</span> <span class="ow">in</span> <span class="n">entry</span><span class="p">:</span>
        <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s1">&#39;eval_loss&#39;</span><span class="p">])</span>
        
        <span class="k">if</span> <span class="s1">&#39;eval_f1_weighted&#39;</span> <span class="ow">in</span> <span class="n">entry</span><span class="p">:</span>
            <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s1">&#39;eval_f1_weighted&#39;</span><span class="p">])</span>

<span class="c1"># Asegurar que todas las listas tengan la misma longitud</span>
<span class="n">min_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">history_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">history_dict</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">min_length</span><span class="p">:</span>
        <span class="n">history_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][:</span><span class="n">min_length</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📋 Resumen del historial:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">history_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span><span class="si">}</span><span class="s2"> registros&quot;</span><span class="p">)</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># 9. GRAFICAR HISTORIAL DE ENTRENAMIENTO</span>
<span class="c1"># ============================================================================</span>

<span class="n">color_train</span> <span class="o">=</span> <span class="s2">&quot;#9c69c2&quot;</span>  
<span class="n">color_val</span> <span class="o">=</span> <span class="s2">&quot;#D5C7EF&quot;</span>    

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">📊 Generando gráficas de entrenamiento para DistilBERT...&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="c1"># ------------------ Pérdida ------------------</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

<span class="c1"># ------------------ F1 Weighted ------------------</span>
<span class="c1"># ------------------ F1 Weighted ------------------</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;f1_weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train F1 (Weighted)&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="n">color_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation F1 (Weighted)&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="n">color_val</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model F1-Score (Weighted)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F1-Score (Weighted)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="c1"># &gt;&gt; ESTA ES LA LÍNEA AÑADIDA PARA FIJAR EL LÍMITE DEL EJE Y</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> 
<span class="c1"># &lt;&lt;</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;#fafafa&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">path_save</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="s2">&quot;distilbert_training_history.png&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path_save</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
📊 GENERANDO VISUALIZACIONES DEL ENTRENAMIENTO
======================================================================

📋 Resumen del historial:
  - loss: 16 registros
  - val_loss: 16 registros
  - f1_weighted: 16 registros
  - val_f1_weighted: 16 registros

📊 Generando gráficas de entrenamiento para DistilBERT...
</pre></div>
</div>
<img alt="_images/83c869d7e31d46dfdfc1d26ab5ea60098ac93adf571c773b5538ca05be5bc699.png" src="_images/83c869d7e31d46dfdfc1d26ab5ea60098ac93adf571c773b5538ca05be5bc699.png" />
</div>
</div>
<p>El proceso de <strong>fine-tuning</strong> de <strong>DistilBERT</strong> resultó en una <strong>rápida convergencia</strong>, alcanzando un <span class="math notranslate nohighlight">\(F1\text{-}Score_{Weighted}\)</span> máximo de <span class="math notranslate nohighlight">\(0.8914\)</span> en la <strong>Época</strong> <span class="math notranslate nohighlight">\(11\)</span>. La estabilidad de la <span class="math notranslate nohighlight">\(Validation\ Loss\)</span> (<span class="math notranslate nohighlight">\(\approx 0.6\)</span>) y el continuo descenso de la <span class="math notranslate nohighlight">\(Training\ Loss\)</span> a valores cercanos a <span class="math notranslate nohighlight">\(0\)</span> (Época <span class="math notranslate nohighlight">\(16\)</span>) confirma la presencia de <strong>sobreajuste</strong>. El <span class="math notranslate nohighlight">\(EarlyStoppingCallback\)</span> detuvo el proceso eficientemente en la <strong>Época</strong> <span class="math notranslate nohighlight">\(16\)</span>, asegurando la selección de la iteración con la mejor <strong>capacidad de generalización</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 6. Evaluación en el Test Set</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_dataset_hf</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">label_ids</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;processed_data/X_test_texts.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">test_texts</span> <span class="o">=</span> <span class="n">X_test</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_dataset_hf</span><span class="p">)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Resultados Finales en el Test Set (DistilBERT) ---&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Resultados Finales en el Test Set (DistilBERT) ---
accuracy: 0.9102
f1_weighted: 0.9094
f1_macro: 0.9073
precision_weighted: 0.9138
recall_weighted: 0.9102
roc_auc_macro: 0.9917
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>DistilBERT</strong>, seleccionado según el mejor <span class="math notranslate nohighlight">\(F1\)</span>-<span class="math notranslate nohighlight">\(Score_{Weighted}\)</span> en el conjunto de validación (Época <span class="math notranslate nohighlight">\(11\)</span>), fue evaluado sobre el conjunto de <strong>prueba</strong>, el cual conserva la distribución original y desbalanceada de clases.</p>
<section id="metricas-de-rendimiento-en-el-conjunto-de-prueba">
<h3>Métricas de rendimiento en el conjunto de prueba<a class="headerlink" href="#metricas-de-rendimiento-en-el-conjunto-de-prueba" title="Permalink to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Métrica</strong></p></th>
<th class="head"><p><strong>Valor</strong></p></th>
<th class="head"><p><strong>Observación Técnica</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Accuracy (Exactitud)</p></td>
<td><p>91.02 %</p></td>
<td><p>Alta tasa de aciertos globales.</p></td>
</tr>
<tr class="row-odd"><td><p>F1-Score Weighted</p></td>
<td><p>90.94 %</p></td>
<td><p>Métrica clave: alto rendimiento ponderado por el soporte real de las clases.</p></td>
</tr>
<tr class="row-even"><td><p>F1-Score Macro</p></td>
<td><p>90.73 %</p></td>
<td><p>Rendimiento equilibrado entre clases, reflejando la eficacia del <em>data augmentation</em>.</p></td>
</tr>
<tr class="row-odd"><td><p>Precision Weighted</p></td>
<td><p>91.38 %</p></td>
<td><p>Alta fiabilidad en las predicciones positivas.</p></td>
</tr>
<tr class="row-even"><td><p>Recall Weighted</p></td>
<td><p>91.02 %</p></td>
<td><p>Elevada capacidad para detectar instancias positivas.</p></td>
</tr>
<tr class="row-odd"><td><p>ROC AUC Macro</p></td>
<td><p>99.17 %</p></td>
<td><p>Excelente capacidad discriminativa entre las 24 clases.</p></td>
</tr>
</tbody>
</table>
</div>
<p>El modelo exhibe una <strong>generalización sobresaliente</strong>, alcanzando un <span class="math notranslate nohighlight">\(F1\)</span>-<span class="math notranslate nohighlight">\(Score_{Weighted}\)</span> de <strong>90.94 %</strong> en el conjunto de prueba, superior al máximo obtenido durante la validación (0.8914).</p>
<ul class="simple">
<li><p><strong>Balance y robustez:</strong> La convergencia entre los valores de <span class="math notranslate nohighlight">\(F1_{Weighted}\)</span> (90.94 %) y <span class="math notranslate nohighlight">\(F1_{Macro}\)</span> (90.73 %) confirma la efectividad del <em>fine-tuning</em> y de la <strong>pérdida ponderada</strong>, logrando un rendimiento casi uniforme entre las 24 clases.</p></li>
<li><p><strong>Capacidad discriminativa:</strong> El <span class="math notranslate nohighlight">\(ROC\ AUC_{Macro}\)</span> de 99.17 % evidencia una excelente separación entre clases y la solidez de las <strong>representaciones contextuales</strong> aprendidas.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_matriz_confusion</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">category_map</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Matriz de Confusión - DistilBERT</span><span class="se">\n</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/235679cba87c81039988db8cebaf57ec00823654b65cb44cc96af6303d5d43de.png" src="_images/235679cba87c81039988db8cebaf57ec00823654b65cb44cc96af6303d5d43de.png" />
</div>
</div>
<p>El análisis de la <strong>Matriz de Confusión</strong> muestra que el modelo clasifica correctamente la gran mayoría de las instancias dentro de las <strong>20 categorías profesionales</strong> definidas, con los errores de clasificación concentrados principalmente en <strong>confusiones lógicas entre clases semánticamente relacionadas</strong>.</p>
<p>La <strong>diagonal principal</strong> de la matriz presenta conteos dominantes de <strong>Verdaderos Positivos</strong>, lo que refleja una alta <strong>Sensibilidad (Recall)</strong> y <strong>Precisión (Precision)</strong> para la mayoría de las clases. Además, se observan <strong>categorías que alcanzan una clasificación perfecta (100 %)</strong>, evidenciando la solidez del modelo para distinguir patrones bien definidos en ciertas profesiones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">mostrar_curvas_roc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">y_prob</span><span class="o">=</span><span class="n">probs</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="s2">&quot;Curvas ROC por clase - DistilBERT&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/59c4124927cc544c389a077a6907c84827ecfe8d70cd157d431461d5287491ff.png" src="_images/59c4124927cc544c389a077a6907c84827ecfe8d70cd157d431461d5287491ff.png" />
</div>
</div>
<p>El análisis de las <strong>Curvas ROC</strong> confirma que el modelo <strong>DistilBERT</strong> posee una <strong>capacidad predictiva excepcional</strong> para la tarea de clasificación. Los valores de <strong>AUC</strong> cercanos o iguales a <strong>1.00</strong> indican que el modelo asigna consistentemente una <strong>probabilidad más alta a las instancias de la clase positiva</strong> que a las de la clase negativa, prácticamente en todas las categorías.</p>
<p>En términos prácticos, esto demuestra que el modelo es <strong>altamente confiable al clasificar nuevas instancias</strong>, y que sus <strong>puntuaciones de confianza (probabilidades)</strong> son <strong>estadísticamente significativas y coherentes</strong> con las verdaderas etiquetas, validando la solidez de su comportamiento probabilístico.</p>
</section>
<section id="analisis-de-errores">
<h3>Análisis de errores<a class="headerlink" href="#analisis-de-errores" title="Permalink to this heading">#</a></h3>
<p>En esta sección se realiza un análisis detallado del rendimiento del modelo más allá de las métricas agregadas. Primero, se calcula el número total de errores, la tasa de error y el accuracy global sobre el conjunto de prueba. Luego, se examina el desempeño por clase, identificando cuántos ejemplos fueron mal clasificados en cada categoría y calculando el accuracy específico por clase, lo que permite detectar posibles sesgos o debilidades del modelo en clases minoritarias.</p>
<p>Finalmente, se analizan las confusiones más frecuentes, es decir, los pares de clases en los que el modelo tiende a equivocarse con mayor regularidad. Este análisis es clave para entender patrones de ambigüedad semántica entre categorías y orientar futuras mejoras en el preprocesamiento, la arquitectura o el balance de clases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analizar_errores</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">category_map</span><span class="p">,</span>
    <span class="n">nombre_modelo</span><span class="o">=</span><span class="s2">&quot;DistilBERT&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
 RESUMEN DE ERRORES - DistilBERT
============================================================
 Predicciones correctas: 365
 Predicciones incorrectas: 36
 Total de ejemplos: 401
 Accuracy: 91.02%
 Tasa de error: 8.98%
============================================================

 ERRORES POR CLASE:
------------------------------------------------------------
ACCOUNTANT               : 0/18 errores (100.00% accuracy)
ADVOCATE                 : 1/18 errores (94.44% accuracy)
AGRICULTURE              : 3/15 errores (80.00% accuracy)
APPAREL                  : 4/15 errores (73.33% accuracy)
ARTS                     : 4/15 errores (73.33% accuracy)
AUTOMOBILE               : 0/15 errores (100.00% accuracy)
AVIATION                 : 3/18 errores (83.33% accuracy)
BANKING                  : 5/17 errores (70.59% accuracy)
BPO                      : 0/15 errores (100.00% accuracy)
BUSINESS-DEVELOPMENT     : 0/18 errores (100.00% accuracy)
CHEF                     : 2/18 errores (88.89% accuracy)
CONSTRUCTION             : 0/17 errores (100.00% accuracy)
CONSULTANT               : 1/17 errores (94.12% accuracy)
DESIGNER                 : 0/16 errores (100.00% accuracy)
DIGITAL-MEDIA            : 3/14 errores (78.57% accuracy)
ENGINEERING              : 1/18 errores (94.44% accuracy)
FINANCE                  : 0/18 errores (100.00% accuracy)
FITNESS                  : 2/18 errores (88.89% accuracy)
HEALTHCARE               : 2/17 errores (88.24% accuracy)
HR                       : 0/17 errores (100.00% accuracy)
INFORMATION-TECHNOLOGY   : 0/18 errores (100.00% accuracy)
PUBLIC-RELATIONS         : 2/17 errores (88.24% accuracy)
SALES                    : 3/17 errores (82.35% accuracy)
TEACHER                  : 0/15 errores (100.00% accuracy)

 CONFUSIONES MÁS COMUNES:
------------------------------------------------------------
BANKING → ARTS: 2 veces (5.6% de errores)
AGRICULTURE → BANKING: 2 veces (5.6% de errores)
FITNESS → APPAREL: 2 veces (5.6% de errores)
SALES → CONSTRUCTION: 2 veces (5.6% de errores)
ADVOCATE → APPAREL: 1 veces (2.8% de errores)
DIGITAL-MEDIA → ARTS: 1 veces (2.8% de errores)
AVIATION → INFORMATION-TECHNOLOGY: 1 veces (2.8% de errores)
APPAREL → BANKING: 1 veces (2.8% de errores)
BANKING → CONSULTANT: 1 veces (2.8% de errores)
AGRICULTURE → APPAREL: 1 veces (2.8% de errores)
</pre></div>
</div>
</div>
</div>
<p>Los errores del modelo <strong>DistilBERT</strong> revelan <strong>patrones de confusión entre clases con proximidad semántica o vocabulario compartido</strong>.<br />
La clase <strong>BANKING</strong> presentó el mayor número de errores (5), principalmente confundida con <strong>ARTS</strong> y <strong>CONSULTANT</strong>, lo que sugiere <strong>ambigüedad léxica</strong> o la presencia de <strong>términos genéricos</strong> en las descripciones.</p>
<p>La categoría <strong>AGRICULTURE</strong> también mostró errores recurrentes, siendo confundida con <strong>BANKING</strong> y <strong>APPAREL</strong>, posiblemente debido a descripciones que incluyen <strong>aspectos económicos o de producción</strong>. Por su parte, <strong>FITNESS</strong> fue mal clasificada como <strong>APPAREL</strong>, lo que podría atribuirse a <strong>menciones de ropa deportiva o estilo de vida activo</strong>. Asimismo, <strong>SALES</strong> fue confundida con <strong>CONSTRUCTION</strong>, indicando textos centrados en <strong>ventas técnicas o industriales</strong>.</p>
<p>Otros errores como <strong>ADVOCATE → APPAREL</strong> y <strong>DIGITAL-MEDIA → ARTS</strong> reflejan <strong>solapamientos en el lenguaje creativo o profesional</strong>.</p>
<p>En conjunto, estos resultados sugieren que el modelo podría beneficiarse de:</p>
<ul class="simple">
<li><p>un <strong>refinamiento en la representación contextual</strong>,</p></li>
<li><p>una <strong>mayor especificidad en los datos de entrenamiento</strong>, y</p></li>
<li><p><strong>estrategias adicionales</strong> para manejar clases con <strong>vocabulario ambiguo o compartido</strong>.</p></li>
</ul>
</section>
</section>
<section id="modelo-2-word2vec-bilstm">
<h2>Modelo 2: Word2Vec + BiLSTM<a class="headerlink" href="#modelo-2-word2vec-bilstm" title="Permalink to this heading">#</a></h2>
<p>El modelo implementado combina representaciones semánticas preentrenadas (<strong>Word2Vec</strong>) con una arquitectura secuencial basada en redes neuronales recurrentes bidireccionales (<strong>BiLSTM</strong>), orientada a tareas de <strong>clasificación multiclase</strong> sobre texto preprocesado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-11-05 18:26:56.266225: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-05 18:26:56.644849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-05 18:26:58.047034: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- CONFIGURACIÓN ---</span>
<span class="n">RESULTS_DIR</span> <span class="o">=</span> <span class="s1">&#39;results_word2vec_bilstm&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>La implementación sigue un flujo de trabajo estándar en clasificación de texto, donde las secuencias ya tokenizadas y de longitud uniforme (<code class="docutils literal notranslate"><span class="pre">max_len</span></code>), junto con el vocabulario, definen la entrada al modelo. La salida corresponde a un problema de clasificación multiclase con etiquetas <strong>One-Hot</strong> (<code class="docutils literal notranslate"><span class="pre">num_classes</span></code>). El modelo emplea una <strong>capa Embedding</strong> de 100 dimensiones, seguida de <strong>dos capas Bi-LSTM</strong> con 128 unidades cada una, lo que permite capturar dependencias contextuales bidireccionales en el texto. Para reducir el sobreajuste observado durante el entrenamiento, se incorpora un <strong>Dropout del 30%</strong> (<code class="docutils literal notranslate"><span class="pre">dropout_rate</span> <span class="pre">=</span> <span class="pre">0.3</span></code>), mientras que la optimización se realiza con una <strong>tasa de aprendizaje inicial de 0.001</strong>, equilibrando estabilidad y velocidad de convergencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FINAL_PARAMS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;lstm_units&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> 
    <span class="s1">&#39;num_lstm_layers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> 
    <span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> 
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.005</span><span class="p">,</span> 
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> 
    <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> 
    <span class="s1">&#39;embedding_dim&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> 
    <span class="c1"># Aumentar paciencia para el 100% de los datos</span>
    <span class="s1">&#39;early_stopping_patience&#39;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> 
    <span class="s1">&#39;reduce_lr_patience&#39;</span><span class="p">:</span> <span class="mi">5</span>      
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Cargar datos</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Cargando datos preprocesados...&quot;</span><span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/word2vec_bilstm_train.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">val_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/word2vec_bilstm_val.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/word2vec_bilstm_test.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;processed_data/word2vec_bilstm_tokenizer.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y_train_cat</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">y_val_cat</span> <span class="o">=</span> <span class="n">y_val</span>
<span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">y_test</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Cargando datos preprocesados...
</pre></div>
</div>
</div>
</div>
<p>El corazón de la arquitectura se basa en el uso de <strong>dos capas Bi-LSTM con 128 unidades</strong> cada una, diseñadas para capturar dependencias contextuales tanto hacia adelante como hacia atrás: la <strong>primera capa devuelve secuencias</strong> (<code class="docutils literal notranslate"><span class="pre">return_sequences=True</span></code>) para alimentar la segunda, mientras que la <strong>segunda capa devuelve solo el estado final</strong> (<code class="docutils literal notranslate"><span class="pre">return_sequences=False</span></code>), condensando la información de toda la frase. Para mitigar el sobreajuste y la sensibilidad a secuencias largas, se utiliza una combinación de <strong>Dropout y SpatialDropout1D al 30%</strong>. La salida final de las capas recurrentes se canaliza a través de un clasificador <em>feed-forward</em> compuesto por dos <strong>capas densas</strong> (128 y 64 unidades, ambas con activación ‘relu’), donde se aplica <strong>Dropout adicional</strong> para reforzar la robustez del modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_bilstm_model</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> 
                       <span class="n">lstm_units</span><span class="p">,</span> <span class="n">num_lstm_layers</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Word2Vec_BiLSTM_Final&#39;</span><span class="p">)</span>
    
    <span class="c1"># Capa de Embedding</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
        <span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;embedding&#39;</span>
    <span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">SpatialDropout1D</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    
    <span class="c1"># Capas BiLSTM</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_lstm_layers</span><span class="p">):</span>
        <span class="c1"># return_sequences=True para todas las capas excepto la última</span>
        <span class="n">return_sequences</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_lstm_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Bidirectional</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
                <span class="n">lstm_units</span><span class="p">,</span>
                <span class="n">return_sequences</span><span class="o">=</span><span class="n">return_sequences</span><span class="p">,</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">recurrent_dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;lstm_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;bilstm_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">))</span>
        
        <span class="k">if</span> <span class="n">return_sequences</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    
    <span class="c1"># Capas densas de clasificación</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense1&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense2&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    
    <span class="c1"># Capa de salida</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>La instancia final del modelo <strong>Bi-LSTM</strong> se configuró para un problema de <strong>clasificación de 24 clases</strong> con la pérdida <strong><code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code></strong> y el optimizador <strong>Adam</strong>, centrándose críticamente en la métrica personalizada <strong>F1-Score Ponderado</strong> (<code class="docutils literal notranslate"><span class="pre">val_f1_weighted</span></code>). Para gestionar el sobreajuste y garantizar la mejor convergencia, se implementó una sólida estrategia de <em>callbacks</em> que monitorea activamente el <strong>máximo</strong> de esta métrica: el <strong>Early Stopping</strong> previene la memorización excesiva restaurando los mejores pesos, el <strong>ReduceLROnPlateau</strong> afina el proceso de optimización disminuyendo la tasa de aprendizaje si el rendimiento se estanca, y el <strong>Model Checkpoint</strong> garantiza que solo se guarde la versión del modelo que logró el F1-Score más alto en el conjunto de validación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. INSTANCIA, COMPILACIÓN Y CALLBACKS</span>
<span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_bilstm_model</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">],</span>
    <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span>
    <span class="n">lstm_units</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;lstm_units&#39;</span><span class="p">],</span>
    <span class="n">num_lstm_layers</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;num_lstm_layers&#39;</span><span class="p">],</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">f1_metric</span> <span class="o">=</span> <span class="n">F1WeightedScore</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">f1_metric</span><span class="p">]</span> 
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Resumen del Modelo Final (Optimizado para F1-Weighted):&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Configurando callbacks para optimizar F1-Weighted...&quot;</span><span class="p">)</span>

<span class="n">callbacks_final</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">,</span> 
        <span class="n">patience</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;early_stopping_patience&#39;</span><span class="p">],</span>
        <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span> 
    <span class="p">),</span>

    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">,</span>
        <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;reduce_lr_patience&#39;</span><span class="p">],</span>
        <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span> 
    <span class="p">),</span>

    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;final_best_f1_model.keras&#39;</span><span class="p">),</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_f1_weighted&#39;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span> 
    <span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Resumen del Modelo Final (Optimizado para F1-Weighted):
</pre></div>
</div>
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "Word2Vec_BiLSTM_Final"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ embedding (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)           │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1200</span>, <span style="color: #00af00; text-decoration-color: #00af00">100</span>)      │     <span style="color: #00af00; text-decoration-color: #00af00">3,414,600</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ spatial_dropout1d               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1200</span>, <span style="color: #00af00; text-decoration-color: #00af00">100</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">SpatialDropout1D</span>)              │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ bilstm_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Bidirectional</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │        <span style="color: #00af00; text-decoration-color: #00af00">34,048</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">8,320</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,256</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ output (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">24</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">1,560</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">3,466,784</span> (13.22 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">3,466,784</span> (13.22 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Configurando callbacks para optimizar F1-Weighted...
</pre></div>
</div>
</div>
</div>
<p>Aquí empezaremos la <strong>ejecución formal del entrenamiento</strong>, donde el modelo Bi-LSTM configurado finalmente se ajusta a los datos de entrenamiento (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train_cat</span></code>) utilizando los hiperparámetros optimizados (<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">epochs</span></code> máximos) y se evalúa constantemente en los datos de validación. La clave es el uso de los <em>callbacks</em> previamente definidos, que <strong>detendrán el proceso prematuramente</strong> si el rendimiento de <strong>F1-Score Ponderado de validación</strong> se estanca (Early Stopping), garantizando que el modelo no exceda el punto óptimo de generalización (evitando el sobreajuste) y registrando el tiempo total y el número real de épocas ejecutadas para la documentación del rendimiento.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5. ENTRENAMIENTO</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  INICIANDO ENTRENAMIENTO FINAL (LR: </span><span class="si">{</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val_cat</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks_final</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="n">epochs_trained</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Entrenamiento final completado!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - Tiempo total: </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s (</span><span class="si">{</span><span class="n">training_time</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - Epochs ejecutados: </span><span class="si">{</span><span class="n">epochs_trained</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
  INICIANDO ENTRENAMIENTO FINAL (LR: 0.005)
======================================================================
Epoch 1/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16s/step - accuracy: 0.0731 - f1_weighted: 0.0488 - loss: 3.1294 
Epoch 1: val_f1_weighted improved from None to 0.27140, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">979s</span> 17s/step - accuracy: 0.1284 - f1_weighted: 0.1003 - loss: 2.9614 - val_accuracy: 0.3741 - val_f1_weighted: 0.2714 - val_loss: 2.0975 - learning_rate: 0.0050
Epoch 2/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.4065 - f1_weighted: 0.3470 - loss: 2.0086 
Epoch 2: val_f1_weighted improved from 0.27140 to 0.60640, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">948s</span> 16s/step - accuracy: 0.4607 - f1_weighted: 0.4127 - loss: 1.8558 - val_accuracy: 0.6434 - val_f1_weighted: 0.6064 - val_loss: 1.3776 - learning_rate: 0.0050
Epoch 3/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.6515 - f1_weighted: 0.6287 - loss: 1.2262 
Epoch 3: val_f1_weighted improved from 0.60640 to 0.62999, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">963s</span> 16s/step - accuracy: 0.6415 - f1_weighted: 0.6220 - loss: 1.2713 - val_accuracy: 0.6559 - val_f1_weighted: 0.6300 - val_loss: 1.1958 - learning_rate: 0.0050
Epoch 4/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.7157 - f1_weighted: 0.7036 - loss: 0.9849 
Epoch 4: val_f1_weighted improved from 0.62999 to 0.68012, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">954s</span> 16s/step - accuracy: 0.7170 - f1_weighted: 0.7075 - loss: 0.9622 - val_accuracy: 0.6958 - val_f1_weighted: 0.6801 - val_loss: 1.1809 - learning_rate: 0.0050
Epoch 5/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.7569 - f1_weighted: 0.7532 - loss: 0.8192 
Epoch 5: val_f1_weighted improved from 0.68012 to 0.69917, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">959s</span> 16s/step - accuracy: 0.7764 - f1_weighted: 0.7720 - loss: 0.7903 - val_accuracy: 0.7107 - val_f1_weighted: 0.6992 - val_loss: 1.2163 - learning_rate: 0.0050
Epoch 6/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.7991 - f1_weighted: 0.7963 - loss: 0.6687 
Epoch 6: val_f1_weighted improved from 0.69917 to 0.70595, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">962s</span> 16s/step - accuracy: 0.8047 - f1_weighted: 0.8022 - loss: 0.6669 - val_accuracy: 0.7207 - val_f1_weighted: 0.7059 - val_loss: 1.2771 - learning_rate: 0.0050
Epoch 7/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.8440 - f1_weighted: 0.8404 - loss: 0.5264 
Epoch 7: val_f1_weighted improved from 0.70595 to 0.70804, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">947s</span> 16s/step - accuracy: 0.8454 - f1_weighted: 0.8439 - loss: 0.5415 - val_accuracy: 0.7182 - val_f1_weighted: 0.7080 - val_loss: 1.3389 - learning_rate: 0.0050
Epoch 8/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.8720 - f1_weighted: 0.8690 - loss: 0.4045 
Epoch 8: val_f1_weighted improved from 0.70804 to 0.71449, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">960s</span> 16s/step - accuracy: 0.8743 - f1_weighted: 0.8729 - loss: 0.4173 - val_accuracy: 0.7157 - val_f1_weighted: 0.7145 - val_loss: 1.4911 - learning_rate: 0.0050
Epoch 9/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16s/step - accuracy: 0.8962 - f1_weighted: 0.8959 - loss: 0.3249 
Epoch 9: val_f1_weighted improved from 0.71449 to 0.72212, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">974s</span> 17s/step - accuracy: 0.8957 - f1_weighted: 0.8951 - loss: 0.3454 - val_accuracy: 0.7257 - val_f1_weighted: 0.7221 - val_loss: 1.6332 - learning_rate: 0.0050
Epoch 10/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.8956 - f1_weighted: 0.8941 - loss: 0.3349 
Epoch 10: val_f1_weighted improved from 0.72212 to 0.72319, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">959s</span> 16s/step - accuracy: 0.8946 - f1_weighted: 0.8937 - loss: 0.3560 - val_accuracy: 0.7307 - val_f1_weighted: 0.7232 - val_loss: 1.6095 - learning_rate: 0.0050
Epoch 11/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9118 - f1_weighted: 0.9114 - loss: 0.2882 
Epoch 11: val_f1_weighted did not improve from 0.72319
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">957s</span> 16s/step - accuracy: 0.9080 - f1_weighted: 0.9076 - loss: 0.2951 - val_accuracy: 0.7307 - val_f1_weighted: 0.7219 - val_loss: 1.7423 - learning_rate: 0.0050
Epoch 12/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9344 - f1_weighted: 0.9340 - loss: 0.2239 
Epoch 12: val_f1_weighted improved from 0.72319 to 0.73422, saving model to results_word2vec_bilstm/final_best_f1_model.keras
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">950s</span> 16s/step - accuracy: 0.9246 - f1_weighted: 0.9244 - loss: 0.2469 - val_accuracy: 0.7332 - val_f1_weighted: 0.7342 - val_loss: 1.8857 - learning_rate: 0.0050
Epoch 13/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9296 - f1_weighted: 0.9294 - loss: 0.2354 
Epoch 13: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">950s</span> 16s/step - accuracy: 0.9304 - f1_weighted: 0.9299 - loss: 0.2349 - val_accuracy: 0.7307 - val_f1_weighted: 0.7257 - val_loss: 1.8454 - learning_rate: 0.0050
Epoch 14/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9440 - f1_weighted: 0.9442 - loss: 0.2122 
Epoch 14: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">951s</span> 16s/step - accuracy: 0.9379 - f1_weighted: 0.9376 - loss: 0.2285 - val_accuracy: 0.7207 - val_f1_weighted: 0.7154 - val_loss: 1.7670 - learning_rate: 0.0050
Epoch 15/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9400 - f1_weighted: 0.9409 - loss: 0.2033 
Epoch 15: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">949s</span> 16s/step - accuracy: 0.9422 - f1_weighted: 0.9421 - loss: 0.2020 - val_accuracy: 0.7257 - val_f1_weighted: 0.7194 - val_loss: 1.8798 - learning_rate: 0.0050
Epoch 16/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9527 - f1_weighted: 0.9528 - loss: 0.1389 
Epoch 16: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">945s</span> 16s/step - accuracy: 0.9481 - f1_weighted: 0.9479 - loss: 0.1637 - val_accuracy: 0.7107 - val_f1_weighted: 0.7070 - val_loss: 2.0442 - learning_rate: 0.0050
Epoch 17/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9438 - f1_weighted: 0.9431 - loss: 0.1816 
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.

Epoch 17: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">945s</span> 16s/step - accuracy: 0.9508 - f1_weighted: 0.9508 - loss: 0.1657 - val_accuracy: 0.7257 - val_f1_weighted: 0.7159 - val_loss: 1.9964 - learning_rate: 0.0050
Epoch 18/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9628 - f1_weighted: 0.9615 - loss: 0.1178 
Epoch 18: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">958s</span> 16s/step - accuracy: 0.9690 - f1_weighted: 0.9689 - loss: 0.1054 - val_accuracy: 0.7207 - val_f1_weighted: 0.7134 - val_loss: 2.2082 - learning_rate: 0.0025
Epoch 19/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9654 - f1_weighted: 0.9649 - loss: 0.0987 
Epoch 19: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">949s</span> 16s/step - accuracy: 0.9706 - f1_weighted: 0.9705 - loss: 0.0887 - val_accuracy: 0.7057 - val_f1_weighted: 0.6991 - val_loss: 2.3410 - learning_rate: 0.0025
Epoch 20/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9780 - f1_weighted: 0.9776 - loss: 0.0806 
Epoch 20: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">948s</span> 16s/step - accuracy: 0.9781 - f1_weighted: 0.9780 - loss: 0.0832 - val_accuracy: 0.7082 - val_f1_weighted: 0.6997 - val_loss: 2.3719 - learning_rate: 0.0025
Epoch 21/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9800 - f1_weighted: 0.9798 - loss: 0.0736 
Epoch 21: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">947s</span> 16s/step - accuracy: 0.9765 - f1_weighted: 0.9764 - loss: 0.0769 - val_accuracy: 0.7182 - val_f1_weighted: 0.7115 - val_loss: 2.3432 - learning_rate: 0.0025
Epoch 22/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9764 - f1_weighted: 0.9762 - loss: 0.0797 
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.

Epoch 22: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">969s</span> 16s/step - accuracy: 0.9818 - f1_weighted: 0.9818 - loss: 0.0646 - val_accuracy: 0.7057 - val_f1_weighted: 0.6962 - val_loss: 2.4488 - learning_rate: 0.0025
Epoch 23/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9845 - f1_weighted: 0.9845 - loss: 0.0622 
Epoch 23: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">946s</span> 16s/step - accuracy: 0.9818 - f1_weighted: 0.9818 - loss: 0.0683 - val_accuracy: 0.7082 - val_f1_weighted: 0.7033 - val_loss: 2.4697 - learning_rate: 0.0012
Epoch 24/50
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15s/step - accuracy: 0.9830 - f1_weighted: 0.9832 - loss: 0.0518 
Epoch 24: val_f1_weighted did not improve from 0.73422
<span class=" -Color -Color-Bold">59/59</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">955s</span> 16s/step - accuracy: 0.9829 - f1_weighted: 0.9829 - loss: 0.0573 - val_accuracy: 0.7182 - val_f1_weighted: 0.7123 - val_loss: 2.4346 - learning_rate: 0.0012
Epoch 24: early stopping
Restoring model weights from the end of the best epoch: 12.

 Entrenamiento final completado!
   - Tiempo total: 22926.13s (382.10 min)
   - Epochs ejecutados: 24/50
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graficar_historial_entrenamiento</span><span class="p">(</span>
    <span class="n">history</span><span class="p">,</span>
    <span class="n">RESULTS_DIR</span><span class="p">,</span>
    <span class="s2">&quot;BiLSTM_Best_Model&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Generando gráficas de entrenamiento para BiLSTM_Best_Model...
</pre></div>
</div>
<img alt="_images/26ad54f468a803902270c851176a824a214d582f032cbf04fda76b6b0eff4d85.png" src="_images/26ad54f468a803902270c851176a824a214d582f032cbf04fda76b6b0eff4d85.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Gráficas guardadas en: results_word2vec_bilstm/bilstm_best_model_training_history.png
</pre></div>
</div>
</div>
</div>
<p>El modelo exhibió un claro <strong>sobreajuste</strong>, confirmado por la divergencia de las curvas de rendimiento: mientras que la <strong>Pérdida de Entrenamiento</strong> converge a cero y el <strong>F1-Score de Entrenamiento</strong> se aproxima al 1.00, la <strong>Pérdida de Validación</strong> aumenta sostenidamente después de la época 5, y el <strong>F1-Score de Validación</strong> se estabiliza en un rendimiento subóptimo del 70-72%. A pesar de tener implementado el <strong>Early Stopping</strong>, el entrenamiento se extendió hasta la época 24 de 50. Dado que el mejor rendimiento de generalización se alcanzó visiblemente entre las épocas 5 y 10, la detención tardía indica que el hiperparámetro de <strong>paciencia (patience)</strong>, fijado en 12, es <strong>excesivamente permisivo</strong>. Esto resultó en un <strong>consumo innecesario de recursos computacionales</strong> durante las épocas adicionales sin obtener mejoras significativas, aunque el uso de <code class="docutils literal notranslate"><span class="pre">restore_best_weights=True</span></code> garantiza que se recuperó el modelo con el F1-Score máximo de validación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 6. Evaluación en Test</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; EVALUACIÓN FINAL EN TEST SET&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">24</span>

<span class="c1"># Cargar el mejor modelo (el que tuvo el mejor val_f1_weighted)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;final_best_f1_model.keras&#39;</span><span class="p">),</span> 
        <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;F1WeightedScore&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">F1WeightedScore</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)}</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Error al cargar el mejor modelo: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Usando el modelo de la última época entrenada.&quot;</span><span class="p">)</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>

<span class="n">y_pred_probs</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">FINAL_PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Métricas Sklearn (Usamos y_test_indices vs y_pred)</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
    <span class="s1">&#39;Precision (weighted)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Precision (macro)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (weighted)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (macro)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (weighted)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (macro)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="c1"># 🌟 Nuevas métricas AUC-ROC 🌟</span>
    <span class="s1">&#39;AUC-ROC (weighted)&#39;</span><span class="p">:</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
    <span class="s1">&#39;AUC-ROC (macro)&#39;</span><span class="p">:</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">:</span><span class="s2">25</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
 EVALUACIÓN FINAL EN TEST SET
======================================================================
Accuracy                 : 0.7382
Precision (weighted)     : 0.7357
Precision (macro)        : 0.7300
Recall (weighted)        : 0.7382
Recall (macro)           : 0.7351
F1-Score (weighted)      : 0.7342
F1-Score (macro)         : 0.7298
AUC-ROC (weighted)       : 0.9586
AUC-ROC (macro)          : 0.9584
</pre></div>
</div>
</div>
</div>
<p>El <strong>Análisis de la Evaluación Final en Test Set</strong> confirma la robustez del modelo, logrando un rendimiento consistente con el máximo observado en validación. El <strong>F1-Score (weighted) de 0.7342</strong> es el valor más representativo del poder predictivo, validando el éxito de la estrategia de optimización. La <strong>Accuracy de 0.7382</strong> es comparable, y la ligera superioridad de las métricas <em>weighted</em> sobre las <em>macro</em> (e.g., F1-Score: 0.7342 vs. 0.7298) sugiere un mejor manejo de las clases más frecuentes. Destaca el <strong>AUC-ROC (weighted) de 0.9586</strong>, lo que evidencia una <strong>excepcional capacidad de discriminación</strong> entre las 24 categorías, confirmando que el modelo es altamente apto para la tarea de clasificación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_matriz_confusion</span><span class="p">(</span>
    <span class="n">y_test_indices</span><span class="p">,</span> 
    <span class="n">y_pred</span><span class="p">,</span> 
    <span class="n">category_map</span><span class="p">,</span> 
    <span class="n">titulo</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Matriz de Confusión - BiLSTM</span><span class="se">\n</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d2c4c00217b07c66bb9e9b648ab9655d48393d1f8d038e18efa0131848dfa64d.png" src="_images/d2c4c00217b07c66bb9e9b648ab9655d48393d1f8d038e18efa0131848dfa64d.png" />
</div>
</div>
<p>La Matriz de Confusión confirma la <strong>Accuracy general del 73.82%</strong> y valida el rendimiento del modelo en el conjunto de prueba. El patrón de la matriz, caracterizado por valores consistentemente altos a lo largo de la diagonal principal, implica que el modelo posee una <strong>elevada capacidad de discriminación</strong> y acierta en la gran mayoría de las predicciones, demostrando que la arquitectura <strong>Bi-LSTM</strong> ha capturado características esenciales para la clasificación. La alta concentración de aciertos en la diagonal en relación con los errores dispersos fuera de ella sugiere que el modelo ha logrado una <strong>generalización efectiva</strong>, aunque el balance entre las métricas <em>weighted</em> y <em>macro</em> indica que existe un margen para refinar la capacidad de la red para distinguir entre grupos de categorías con solapamiento semántico o funcional.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_curvas_roc</span><span class="p">(</span>
    <span class="n">y_test_indices</span><span class="p">,</span>
    <span class="n">y_pred_probs</span><span class="p">,</span> <span class="c1"># Usamos las probabilidades para ROC</span>
    <span class="n">num_classes</span><span class="p">,</span>
    <span class="s2">&quot;Curvas ROC - Modelo Final BiLSTM (Test Set)&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/33f1993b8c19ed575b5bcf9ba9590f7baf1f5ce6371f99fab2362eb25259a9a5.png" src="_images/33f1993b8c19ed575b5bcf9ba9590f7baf1f5ce6371f99fab2362eb25259a9a5.png" />
</div>
</div>
<p>El gráfico valida que el modelo Bi-LSTM tiene una <strong>alta capacidad de discriminación</strong> en general, con un rendimiento casi perfecto en la mayoría de las categorías. Las clases con un AUC ligeramente menor (especialmente la Clase 17) representan las áreas donde la red requiere ajustes de características para mejorar la separación binaria de sus ejemplos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analizar_errores</span><span class="p">(</span>
    <span class="n">y_test_indices</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">category_map</span><span class="p">,</span>
    <span class="s2">&quot;Modelo Final BiLSTM&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
 RESUMEN DE ERRORES - Modelo Final BiLSTM
============================================================
 Predicciones correctas: 296
 Predicciones incorrectas: 105
 Total de ejemplos: 401
 Accuracy: 73.82%
 Tasa de error: 26.18%
============================================================

 ERRORES POR CLASE:
------------------------------------------------------------
ACCOUNTANT               : 0/18 errores (100.00% accuracy)
ADVOCATE                 : 4/18 errores (77.78% accuracy)
AGRICULTURE              : 4/15 errores (73.33% accuracy)
APPAREL                  : 12/15 errores (20.00% accuracy)
ARTS                     : 11/15 errores (26.67% accuracy)
AUTOMOBILE               : 1/15 errores (93.33% accuracy)
AVIATION                 : 8/18 errores (55.56% accuracy)
BANKING                  : 11/17 errores (35.29% accuracy)
BPO                      : 0/15 errores (100.00% accuracy)
BUSINESS-DEVELOPMENT     : 0/18 errores (100.00% accuracy)
CHEF                     : 3/18 errores (83.33% accuracy)
CONSTRUCTION             : 4/17 errores (76.47% accuracy)
CONSULTANT               : 3/17 errores (82.35% accuracy)
DESIGNER                 : 1/16 errores (93.75% accuracy)
DIGITAL-MEDIA            : 4/14 errores (71.43% accuracy)
ENGINEERING              : 3/18 errores (83.33% accuracy)
FINANCE                  : 0/18 errores (100.00% accuracy)
FITNESS                  : 12/18 errores (33.33% accuracy)
HEALTHCARE               : 7/17 errores (58.82% accuracy)
HR                       : 0/17 errores (100.00% accuracy)
INFORMATION-TECHNOLOGY   : 3/18 errores (83.33% accuracy)
PUBLIC-RELATIONS         : 8/17 errores (52.94% accuracy)
SALES                    : 4/17 errores (76.47% accuracy)
TEACHER                  : 2/15 errores (86.67% accuracy)

 CONFUSIONES MÁS COMUNES:
------------------------------------------------------------
APPAREL → FITNESS: 4 veces (3.8% de errores)
BANKING → APPAREL: 2 veces (1.9% de errores)
BANKING → AUTOMOBILE: 2 veces (1.9% de errores)
ARTS → BANKING: 2 veces (1.9% de errores)
ARTS → ADVOCATE: 2 veces (1.9% de errores)
CONSTRUCTION → PUBLIC-RELATIONS: 2 veces (1.9% de errores)
HEALTHCARE → APPAREL: 2 veces (1.9% de errores)
ADVOCATE → HEALTHCARE: 2 veces (1.9% de errores)
PUBLIC-RELATIONS → AGRICULTURE: 2 veces (1.9% de errores)
HEALTHCARE → PUBLIC-RELATIONS: 2 veces (1.9% de errores)
</pre></div>
</div>
</div>
</div>
<p>El análisis detallado de errores confirma la <strong>Accuracy global de 73.82%</strong> con 105 errores, cuya distribución es altamente heterogénea. Si bien el modelo logra una <strong>clasificación perfecta (100% de Accuracy)</strong> en clases con límites claros como <strong>ACCOUNTANT</strong>, <strong>BPO</strong>, <strong>FINANCE</strong> y <strong>HR</strong>, un grupo de cuatro categorías (<strong>APPAREL</strong> con 20% de Accuracy, <strong>ARTS</strong>, <strong>FITNESS</strong> y <strong>BANKING</strong>) concentra la mayoría de los fallos, arrastrando las métricas <em>macro</em>. Esta debilidad se debe a la dificultad de la Bi-LSTM para distinguir clases con <strong>solapamiento semántico</strong>, como la principal confusión entre <strong>APPAREL y FITNESS</strong>. Para futuras iteraciones, la <strong>estrategia de mejora debe enfocarse prioritariamente en el subconjunto de clases con rendimiento inferior al 50%</strong>, utilizando técnicas como el ajuste de <em>embeddings</em> para fortalecer la separación de características en estas categorías débiles.</p>
</section>
<section id="modelo-3-cnn-1d-para-texto-con-embeddings-preentrenados">
<h2>Modelo 3: CNN-1D para texto (con embeddings preentrenados)<a class="headerlink" href="#modelo-3-cnn-1d-para-texto-con-embeddings-preentrenados" title="Permalink to this heading">#</a></h2>
<p>El sistema implementa una <strong>Red Neuronal Convolucional 1D (CNN-1D)</strong>, una arquitectura eficiente para la clasificación de texto. La característica fundamental de este modelo es el uso de <strong>Embeddings pre-entrenados (GloVe)</strong> para la representación de palabras.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- CONFIGURACIÓN ---</span>
<span class="n">RESULTS_DIR</span> <span class="o">=</span> <span class="s1">&#39;results_cnn1d&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Se configuró un conjunto de <strong>hiperparámetros clave</strong> para la arquitectura y el entrenamiento del modelo. Los vectores de palabras se representan con <strong>300 dimensiones</strong> (<code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code>), mientras que la red convolucional emplea <strong>128 filtros</strong> por capa con ventanas de tamaño <strong>5</strong> (<code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>) y <strong>3 bloques Conv1D + MaxPooling</strong> (<code class="docutils literal notranslate"><span class="pre">num_conv_layers</span></code>). Se incorpora un <strong>dropout del 30%</strong> (<code class="docutils literal notranslate"><span class="pre">dropout_rate</span></code>) para regularizar el modelo, y el entrenamiento se realiza con una tasa de aprendizaje inicial de <strong>0.001</strong> (<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>) y <strong>batch size de 64</strong> (<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>). Para optimizar la convergencia, se utilizan <strong>mecanismos de parada temprana</strong> (<code class="docutils literal notranslate"><span class="pre">early_stopping_patience</span> <span class="pre">=</span> <span class="pre">5</span></code>) y reducción dinámica de la tasa de aprendizaje (<code class="docutils literal notranslate"><span class="pre">reduce_lr_patience</span> <span class="pre">=</span> <span class="pre">3</span></code>) basados en la evolución de la pérdida de validación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hiperparámetros</span>
<span class="n">PARAMS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;filters&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s1">&#39;kernel_size&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s1">&#39;num_conv_layers&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;embedding_dim&#39;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>  
    <span class="s1">&#39;early_stopping_patience&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s1">&#39;reduce_lr_patience&#39;</span><span class="p">:</span> <span class="mi">3</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Los datos preprocesados se cargan, los cuales ya están tokenizados y paddeados a una longitud máxima (<code class="docutils literal notranslate"><span class="pre">max_len</span></code>).</p>
<ul class="simple">
<li><p><strong>Carga de Datos:</strong> Los conjuntos de <strong>Entrenamiento</strong>, <strong>Validación</strong> y <strong>Test</strong> (<code class="docutils literal notranslate"><span class="pre">X</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>) se cargan desde archivos <code class="docutils literal notranslate"><span class="pre">.npz</span></code>. Los datos de entrada (<code class="docutils literal notranslate"><span class="pre">X</span></code>) son secuencias de índices numéricos.</p></li>
<li><p><strong>Formato de Etiquetas:</strong> Las etiquetas de salida (<code class="docutils literal notranslate"><span class="pre">y</span></code>) están en formato <strong>One-Hot</strong> (<code class="docutils literal notranslate"><span class="pre">y_train_cat</span></code>, etc.), adecuado para la pérdida <code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code>.</p></li>
<li><p><strong>Parámetros Derivados:</strong> Se carga el <strong><code class="docutils literal notranslate"><span class="pre">tokenizer</span></code></strong> para determinar el <strong><code class="docutils literal notranslate"><span class="pre">vocab_size</span></code></strong> (tamaño del vocabulario) y la <strong><code class="docutils literal notranslate"><span class="pre">max_len</span></code></strong> (longitud máxima de la secuencia), cruciales para dimensionar la capa de <em>Embedding</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Cargar datos</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Cargando datos preprocesados...&quot;</span><span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/cnn_1d_train.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">val_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/cnn_1d_val.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;processed_data/cnn_1d_test.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;processed_data/cnn_1d_tokenizer.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y_train_cat</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">y_val_cat</span> <span class="o">=</span> <span class="n">y_val</span>
<span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">y_test</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_test_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Cargando datos preprocesados...
</pre></div>
</div>
</div>
</div>
<p>Se realiza el <strong>Transfer Learning</strong> cargando vectores de palabras con significado semántico ya aprendido.</p>
<ul class="simple">
<li><p><strong>Búsqueda GloVe:</strong> Se intenta cargar los vectores de <span class="math notranslate nohighlight">\(300\)</span> dimensiones desde el archivo <strong><code class="docutils literal notranslate"><span class="pre">glove.6B.300d.txt</span></code></strong>.</p></li>
<li><p><strong>Mapeo:</strong> Si el archivo existe, se crea la <strong><code class="docutils literal notranslate"><span class="pre">embedding_matrix</span></code></strong> de tamaño <span class="math notranslate nohighlight">\(\text{vocab\_size} \times 300\)</span>. Por cada palabra en el vocabulario local, se busca y se copia su vector GloVe en la matriz.</p></li>
<li><p><strong>Inicialización:</strong> Esta matriz será utilizada para inicializar los pesos de la capa de <em>Embedding</em> del modelo. Las palabras no encontradas o que no están en GloVe se inicializan a cero.</p></li>
<li><p><strong>Fallback:</strong> Si GloVe no está disponible, el sistema ajusta la <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code> a <span class="math notranslate nohighlight">\(100\)</span> y la capa de <em>Embedding</em> se entrenará desde cero.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -----------------------------</span>
<span class="c1"># 2. Cargar embeddings GloVe pre-entrenados</span>
<span class="c1"># -----------------------------</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Cargando embeddings GloVe pre-entrenados...&quot;</span><span class="p">)</span>

<span class="n">GLOVE_PATH</span> <span class="o">=</span> <span class="s1">&#39;/home/sara/modelos/glove.6B.300d.txt&#39;</span>

<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">GLOVE_PATH</span><span class="p">):</span>
    
    <span class="c1"># Cargar embeddings</span>
    <span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">GLOVE_PATH</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
            <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
    
    <span class="c1"># Crear matriz de embeddings</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Creando matriz de embeddings...&quot;</span><span class="p">)</span>
    <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">]))</span>
    <span class="n">found_words</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">vocab_size</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
            <span class="n">found_words</span> <span class="o">+=</span> <span class="mi">1</span> 
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Entrenando embeddings desde cero...&quot;</span><span class="p">)</span>
    <span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Cargando embeddings GloVe pre-entrenados...
 Creando matriz de embeddings...
</pre></div>
</div>
</div>
</div>
<p><strong>Arquitectura del Modelo CNN-1D</strong></p>
<ol class="arabic simple">
<li><p><strong>Capa de <em>Embedding</em>:</strong></p>
<ul class="simple">
<li><p>Inicializada con <strong><code class="docutils literal notranslate"><span class="pre">embedding_matrix</span></code></strong> (pesos GloVe).</p></li>
<li><p>Establecida como <strong><code class="docutils literal notranslate"><span class="pre">trainable=False</span></code></strong> para mantener fijos los pesos pre-entrenados, evitando su degradación por el <em>training</em> local.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Dropout(0.3)</span></code>:</strong> Aplicada directamente a la salida de los <em>embeddings</em> para regularización.</p></li>
<li><p><strong>Capas Convolucionales:</strong> Se apilan <strong><span class="math notranslate nohighlight">\(3\)</span> bloques</strong> que realizan:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Conv1D</span></code> (<span class="math notranslate nohighlight">\(128\)</span> filtros, <span class="math notranslate nohighlight">\(\text{kernel\_size}=5\)</span>, ReLU):</strong> Detecta patrones locales (frases cortas).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">MaxPooling1D</span></code> (<span class="math notranslate nohighlight">\(\text{pool\_size}=2\)</span>):</strong> Submuestrea para reducir la secuencia a la mitad y mantener solo las características más relevantes.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Dropout</span></code> (<span class="math notranslate nohighlight">\(0.3\)</span>):</strong> Regularización adicional tras el <em>pooling</em>.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">GlobalMaxPooling1D</span></code>:</strong> Reduce el resultado de la última capa convolucional a un único vector de características de longitud fija, concentrando la información más importante para la clasificación.</p></li>
<li><p><strong>Capas Densa (<em>Feed-Forward</em>):</strong></p>
<ul class="simple">
<li><p>Dos capas densas con activación <strong>ReLU</strong> (<span class="math notranslate nohighlight">\(128\)</span> y <span class="math notranslate nohighlight">\(64\)</span> unidades) procesan el vector de características.</p></li>
<li><p>Una tasa de <em>Dropout</em> elevada (<span class="math notranslate nohighlight">\(0.3 + 0.2 = 0.5\)</span>) se aplica a la primera capa densa.</p></li>
</ul>
</li>
<li><p><strong>Capa de Salida:</strong> <strong><code class="docutils literal notranslate"><span class="pre">Dense</span></code></strong> con <strong><code class="docutils literal notranslate"><span class="pre">num_classes</span></code></strong> y activación <strong>Softmax</strong> para la predicción de probabilidades multiclase.</p></li>
</ol>
<ul class="simple">
<li><p><strong>Compilación:</strong></p>
<ul>
<li><p><strong>Optimizador:</strong> <strong>Adam</strong> (<span class="math notranslate nohighlight">\(\text{lr}=0.001\)</span>).</p></li>
<li><p><strong>Pérdida:</strong> <strong><code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code></strong>.</p></li>
<li><p><strong>Métricas:</strong> <strong><code class="docutils literal notranslate"><span class="pre">f1metric</span></code></strong> y <strong><code class="docutils literal notranslate"><span class="pre">accuracy</span></code></strong>.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Construir modelo CNN-1D con embeddings pre-entrenados</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Construyendo modelo CNN-1D...&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_cnn1d_model</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span>
                      <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">num_conv_layers</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span>
                      <span class="n">embedding_matrix</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construye modelo CNN-1D con embeddings pre-entrenados&quot;&quot;&quot;</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;CNN_1D_GloVe&#39;</span><span class="p">)</span>
    
    <span class="c1"># Capa de Embedding con pesos pre-entrenados</span>
    <span class="k">if</span> <span class="n">embedding_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
            <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span>
            <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;embedding_pretrained&#39;</span>
        <span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Usando embeddings pre-entrenados (congelados)&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
            <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;embedding_trainable&#39;</span>
        <span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Entrenando embeddings desde cero&quot;</span><span class="p">)</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dropout_embedding&#39;</span><span class="p">))</span>
    
    <span class="c1"># Capas convolucionales</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_conv_layers</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span>
            <span class="n">filters</span><span class="o">=</span><span class="n">filters</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;conv1d_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;maxpool_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;dropout_conv_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
    
    <span class="c1"># Global Max Pooling</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalMaxPooling1D</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;global_maxpool&#39;</span><span class="p">))</span>
    
    <span class="c1"># Capas densas</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense1&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dropout_dense1&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense2&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dropout_dense2&#39;</span><span class="p">))</span>
    
    <span class="c1"># Capa de salida</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_cnn1d_model</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">],</span>
    <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">filters</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;filters&#39;</span><span class="p">],</span>
    <span class="n">kernel_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">],</span>
    <span class="n">num_conv_layers</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;num_conv_layers&#39;</span><span class="p">],</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">],</span>
    <span class="n">embedding_matrix</span><span class="o">=</span><span class="n">embedding_matrix</span>  
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>

<span class="n">f1_metric</span> <span class="o">=</span> <span class="n">F1WeightedScore</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Compilar modelo</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">f1_metric</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Resumen del modelo:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Construyendo modelo CNN-1D...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/sara/miniconda3/envs/tf_gpu/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.
  warnings.warn(
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1762212719.403649   83320 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9129 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Usando embeddings pre-entrenados (congelados)

 Resumen del modelo:
</pre></div>
</div>
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "CNN_1D_GloVe"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ embedding_pretrained            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1200</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>)      │    <span style="color: #00af00; text-decoration-color: #00af00">10,243,800</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)                     │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_embedding (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1200</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1200</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)      │       <span style="color: #00af00; text-decoration-color: #00af00">192,128</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ maxpool_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">600</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_conv_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">600</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">600</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │        <span style="color: #00af00; text-decoration-color: #00af00">82,048</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ maxpool_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_conv_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │        <span style="color: #00af00; text-decoration-color: #00af00">82,048</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ maxpool_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">150</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_conv_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">150</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)       │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_maxpool                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalMaxPooling1D</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">16,512</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_dense1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,256</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_dense2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ output (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">24</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">1,560</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">10,626,352</span> (40.54 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">382,552</span> (1.46 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">10,243,800</span> (39.08 MB)
</pre>
</div></div>
</div>
<p>La <strong>convergencia del entrenamiento</strong> fue gestionada mediante tres <em>callbacks</em> que monitorean la <span class="math notranslate nohighlight">\(val\_loss\)</span> para garantizar una mayor estabilidad y evitar el sobreajuste:</p>
<ul class="simple">
<li><p><strong>EarlyStopping</strong> (<span class="math notranslate nohighlight">\(patience = 5\)</span>): detiene el entrenamiento si la pérdida de validación no muestra mejora tras cinco épocas consecutivas.</p></li>
<li><p><strong>ReduceLROnPlateau</strong> (<span class="math notranslate nohighlight">\(patience = 3\)</span>): reduce el <em>learning rate</em> a la mitad cuando la pérdida de validación se estanca.</p></li>
<li><p><strong>ModelCheckpoint</strong>: guarda automáticamente la versión del modelo con la <span class="math notranslate nohighlight">\(val\_loss\)</span> más baja registrada durante el entrenamiento.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Callbacks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Configurando callbacks...&quot;</span><span class="p">)</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;early_stopping_patience&#39;</span><span class="p">],</span>
        <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span>
    <span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;reduce_lr_patience&#39;</span><span class="p">],</span>
        <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span>
    <span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;best_cnn1d_model.keras&#39;</span><span class="p">),</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span>
    <span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Configurando callbacks...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5. Entrenamiento</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ENTRENAMIENTO DEL MODELO&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val_cat</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="n">epochs_trained</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Entrenamiento completado!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - Tiempo: </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s (</span><span class="si">{</span><span class="n">training_time</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   - Epochs: </span><span class="si">{</span><span class="n">epochs_trained</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
ENTRENAMIENTO DEL MODELO
======================================================================
Epoch 1/100
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-11-03 18:32:05.892509: I external/local_xla/xla/service/service.cc:153] XLA service 0x71812c0059c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-11-03 18:32:05.892542: I external/local_xla/xla/service/service.cc:161]   StreamExecutor device (0): NVIDIA GeForce RTX 5070, Compute Capability 12.0
2025-11-03 18:32:05.922286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-03 18:32:05.995706: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:05.996999: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:05.998773: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert
2025-11-03 18:32:06.000253: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert
I0000 00:00:1762212726.085634   83643 cuda_dnn.cc:530] Loaded cuDNN version 90800
2025-11-03 18:32:06.204495: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204545: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204553: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204558: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204563: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204568: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204573: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204577: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:06.204581: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:07.203328: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 136 bytes spill stores, 136 bytes spill loads

2025-11-03 18:32:07.731909: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 112 bytes spill stores, 112 bytes spill loads

2025-11-03 18:32:07.871221: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 12 bytes spill stores, 12 bytes spill loads

2025-11-03 18:32:08.232853: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 184 bytes spill stores, 184 bytes spill loads

2025-11-03 18:32:08.729004: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3573&#39;, 268 bytes spill stores, 268 bytes spill loads

2025-11-03 18:32:08.762503: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 136 bytes spill stores, 136 bytes spill loads

2025-11-03 18:32:08.763804: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2325&#39;, 32 bytes spill stores, 32 bytes spill loads

2025-11-03 18:32:08.837947: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3573&#39;, 264 bytes spill stores, 264 bytes spill loads

2025-11-03 18:32:09.170240: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 40 bytes spill stores, 40 bytes spill loads

2025-11-03 18:32:09.351852: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3557&#39;, 264 bytes spill stores, 264 bytes spill loads

2025-11-03 18:32:09.724871: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 48 bytes spill stores, 48 bytes spill loads

2025-11-03 18:32:10.085042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3589&#39;, 236 bytes spill stores, 236 bytes spill loads

2025-11-03 18:32:10.214333: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 48 bytes spill stores, 48 bytes spill loads

2025-11-03 18:32:10.236617: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3557&#39;, 260 bytes spill stores, 260 bytes spill loads

2025-11-03 18:32:10.238544: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 104 bytes spill stores, 104 bytes spill loads

2025-11-03 18:32:10.280195: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3589&#39;, 236 bytes spill stores, 236 bytes spill loads

2025-11-03 18:32:10.356294: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 104 bytes spill stores, 104 bytes spill loads
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">13/30</span> <span class=" -Color -Color-Green">━━━━━━━━</span><span class=" -Color -Color-White">━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0615 - f1_weighted: 0.0525 - loss: 3.5948
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>I0000 00:00:1762212734.639049   83643 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">25/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0555 - f1_weighted: 0.0491 - loss: 3.4647
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-11-03 18:32:15.081720: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:15.082250: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:15.082969: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert
2025-11-03 18:32:15.083569: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert
2025-11-03 18:32:15.247199: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247248: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247257: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247261: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247264: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247268: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247271: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247274: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.247277: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:15.923954: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 164 bytes spill stores, 164 bytes spill loads

2025-11-03 18:32:15.932110: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2274&#39;, 24 bytes spill stores, 24 bytes spill loads

2025-11-03 18:32:16.134751: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2223&#39;, 24 bytes spill stores, 24 bytes spill loads

2025-11-03 18:32:16.150437: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2223&#39;, 16 bytes spill stores, 16 bytes spill loads

2025-11-03 18:32:16.423023: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 4 bytes spill stores, 4 bytes spill loads

2025-11-03 18:32:16.502640: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2325&#39;, 32 bytes spill stores, 32 bytes spill loads

2025-11-03 18:32:16.779833: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 60 bytes spill stores, 64 bytes spill loads

2025-11-03 18:32:17.236339: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 20 bytes spill stores, 20 bytes spill loads

2025-11-03 18:32:17.365256: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_2274&#39;, 24 bytes spill stores, 24 bytes spill loads

2025-11-03 18:32:17.550603: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3284&#39;, 160 bytes spill stores, 160 bytes spill loads

2025-11-03 18:32:17.580060: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 8 bytes spill stores, 8 bytes spill loads

2025-11-03 18:32:17.746243: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 108 bytes spill stores, 108 bytes spill loads

2025-11-03 18:32:17.866682: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3557&#39;, 168 bytes spill stores, 168 bytes spill loads

2025-11-03 18:32:17.877600: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3557&#39;, 108 bytes spill stores, 108 bytes spill loads

2025-11-03 18:32:17.957757: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3303&#39;, 56 bytes spill stores, 56 bytes spill loads

2025-11-03 18:32:18.374755: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3573&#39;, 168 bytes spill stores, 168 bytes spill loads

2025-11-03 18:32:18.498720: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3573&#39;, 120 bytes spill stores, 120 bytes spill loads

2025-11-03 18:32:18.782121: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 56 bytes spill stores, 56 bytes spill loads

2025-11-03 18:32:19.211455: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_3322&#39;, 128 bytes spill stores, 128 bytes spill loads
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 286ms/step - accuracy: 0.0541 - f1_weighted: 0.0482 - loss: 3.4340
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-11-03 18:32:23.303805: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:23.305186: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:23.306899: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert
2025-11-03 18:32:23.308382: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert
2025-11-03 18:32:23.326789: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:23.326831: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:23.847029: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 84 bytes spill stores, 84 bytes spill loads

2025-11-03 18:32:24.064070: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 76 bytes spill stores, 76 bytes spill loads

2025-11-03 18:32:24.206084: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 92 bytes spill stores, 92 bytes spill loads

2025-11-03 18:32:24.307995: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 136 bytes spill stores, 136 bytes spill loads

2025-11-03 18:32:24.313369: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 80 bytes spill stores, 80 bytes spill loads

2025-11-03 18:32:24.393943: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 32 bytes spill stores, 32 bytes spill loads

2025-11-03 18:32:24.474618: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 124 bytes spill stores, 124 bytes spill loads

2025-11-03 18:32:25.419565: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:25.420083: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert
2025-11-03 18:32:25.420777: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert
2025-11-03 18:32:25.421349: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert
2025-11-03 18:32:25.436286: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:25.436327: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:25.436336: W external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2025-11-03 18:32:26.039035: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_111&#39;, 24 bytes spill stores, 24 bytes spill loads

2025-11-03 18:32:26.087215: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 220 bytes spill stores, 220 bytes spill loads

2025-11-03 18:32:26.368173: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 168 bytes spill stores, 168 bytes spill loads

2025-11-03 18:32:26.387081: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 32 bytes spill stores, 32 bytes spill loads

2025-11-03 18:32:26.428013: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_111&#39;, 24 bytes spill stores, 24 bytes spill loads

2025-11-03 18:32:26.481936: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 64 bytes spill stores, 64 bytes spill loads

2025-11-03 18:32:26.640036: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 76 bytes spill stores, 76 bytes spill loads

2025-11-03 18:32:26.660161: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_118&#39;, 176 bytes spill stores, 176 bytes spill loads

2025-11-03 18:32:26.943977: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 124 bytes spill stores, 124 bytes spill loads

2025-11-03 18:32:26.963010: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function &#39;gemm_fusion_dot_125&#39;, 84 bytes spill stores, 84 bytes spill loads
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: val_loss improved from None to 3.17791, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">23s</span> 458ms/step - accuracy: 0.0465 - f1_weighted: 0.0431 - loss: 3.2768 - val_accuracy: 0.0324 - val_f1_weighted: 0.0056 - val_loss: 3.1779 - learning_rate: 0.0010
Epoch 2/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0332 - f1_weighted: 0.0321 - loss: 3.1791
Epoch 2: val_loss improved from 3.17791 to 3.17693, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.0385 - f1_weighted: 0.0354 - loss: 3.1799 - val_accuracy: 0.0424 - val_f1_weighted: 0.0036 - val_loss: 3.1769 - learning_rate: 0.0010
Epoch 3/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0411 - f1_weighted: 0.0331 - loss: 3.1840
Epoch 3: val_loss did not improve from 3.17693
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.0375 - f1_weighted: 0.0299 - loss: 3.1827 - val_accuracy: 0.0474 - val_f1_weighted: 0.0137 - val_loss: 3.1776 - learning_rate: 0.0010
Epoch 4/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0485 - f1_weighted: 0.0376 - loss: 3.1779
Epoch 4: val_loss improved from 3.17693 to 3.17571, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.0514 - f1_weighted: 0.0394 - loss: 3.1786 - val_accuracy: 0.0474 - val_f1_weighted: 0.0191 - val_loss: 3.1757 - learning_rate: 0.0010
Epoch 5/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0472 - f1_weighted: 0.0431 - loss: 3.1762
Epoch 5: val_loss did not improve from 3.17571
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.0449 - f1_weighted: 0.0407 - loss: 3.1761 - val_accuracy: 0.0499 - val_f1_weighted: 0.0130 - val_loss: 3.1762 - learning_rate: 0.0010
Epoch 6/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0492 - f1_weighted: 0.0394 - loss: 3.1757
Epoch 6: val_loss improved from 3.17571 to 3.16941, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.0519 - f1_weighted: 0.0383 - loss: 3.1734 - val_accuracy: 0.0973 - val_f1_weighted: 0.0476 - val_loss: 3.1694 - learning_rate: 0.0010
Epoch 7/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0462 - f1_weighted: 0.0349 - loss: 3.1660
Epoch 7: val_loss improved from 3.16941 to 3.14725, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.0556 - f1_weighted: 0.0436 - loss: 3.1572 - val_accuracy: 0.0798 - val_f1_weighted: 0.0339 - val_loss: 3.1473 - learning_rate: 0.0010
Epoch 8/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0762 - f1_weighted: 0.0516 - loss: 3.1192
Epoch 8: val_loss improved from 3.14725 to 3.10297, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.0819 - f1_weighted: 0.0614 - loss: 3.1126 - val_accuracy: 0.0773 - val_f1_weighted: 0.0319 - val_loss: 3.1030 - learning_rate: 0.0010
Epoch 9/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.0845 - f1_weighted: 0.0654 - loss: 3.0468
Epoch 9: val_loss improved from 3.10297 to 3.01611, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.0931 - f1_weighted: 0.0720 - loss: 3.0394 - val_accuracy: 0.1372 - val_f1_weighted: 0.0731 - val_loss: 3.0161 - learning_rate: 0.0010
Epoch 10/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.1174 - f1_weighted: 0.0935 - loss: 2.9948
Epoch 10: val_loss improved from 3.01611 to 2.92176, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.1273 - f1_weighted: 0.1006 - loss: 2.9630 - val_accuracy: 0.1646 - val_f1_weighted: 0.0830 - val_loss: 2.9218 - learning_rate: 0.0010
Epoch 11/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.1233 - f1_weighted: 0.0809 - loss: 2.9405
Epoch 11: val_loss improved from 2.92176 to 2.82688, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.1386 - f1_weighted: 0.0977 - loss: 2.8937 - val_accuracy: 0.1646 - val_f1_weighted: 0.0734 - val_loss: 2.8269 - learning_rate: 0.0010
Epoch 12/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.1434 - f1_weighted: 0.0979 - loss: 2.7753
Epoch 12: val_loss improved from 2.82688 to 2.76961, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.1600 - f1_weighted: 0.1137 - loss: 2.7542 - val_accuracy: 0.2219 - val_f1_weighted: 0.1452 - val_loss: 2.7696 - learning_rate: 0.0010
Epoch 13/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.1896 - f1_weighted: 0.1425 - loss: 2.6828
Epoch 13: val_loss improved from 2.76961 to 2.68772, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.1803 - f1_weighted: 0.1387 - loss: 2.6963 - val_accuracy: 0.2369 - val_f1_weighted: 0.1563 - val_loss: 2.6877 - learning_rate: 0.0010
Epoch 14/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.1876 - f1_weighted: 0.1528 - loss: 2.5856
Epoch 14: val_loss improved from 2.68772 to 2.63149, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 17ms/step - accuracy: 0.1942 - f1_weighted: 0.1608 - loss: 2.6189 - val_accuracy: 0.2469 - val_f1_weighted: 0.1739 - val_loss: 2.6315 - learning_rate: 0.0010
Epoch 15/100
<span class=" -Color -Color-Bold">28/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.1937 - f1_weighted: 0.1568 - loss: 2.5865
Epoch 15: val_loss improved from 2.63149 to 2.52820, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 17ms/step - accuracy: 0.2087 - f1_weighted: 0.1704 - loss: 2.5361 - val_accuracy: 0.2843 - val_f1_weighted: 0.2191 - val_loss: 2.5282 - learning_rate: 0.0010
Epoch 16/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.2345 - f1_weighted: 0.2000 - loss: 2.4982
Epoch 16: val_loss did not improve from 2.52820
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.2263 - f1_weighted: 0.1968 - loss: 2.5026 - val_accuracy: 0.2569 - val_f1_weighted: 0.1900 - val_loss: 2.5336 - learning_rate: 0.0010
Epoch 17/100
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.2394 - f1_weighted: 0.1991 - loss: 2.4513
Epoch 17: val_loss improved from 2.52820 to 2.44111, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.2381 - f1_weighted: 0.2033 - loss: 2.4413 - val_accuracy: 0.3242 - val_f1_weighted: 0.2668 - val_loss: 2.4411 - learning_rate: 0.0010
Epoch 18/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.2656 - f1_weighted: 0.2368 - loss: 2.3655
Epoch 18: val_loss improved from 2.44111 to 2.32915, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.2793 - f1_weighted: 0.2485 - loss: 2.3114 - val_accuracy: 0.3416 - val_f1_weighted: 0.2825 - val_loss: 2.3291 - learning_rate: 0.0010
Epoch 19/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.2907 - f1_weighted: 0.2576 - loss: 2.2419
Epoch 19: val_loss improved from 2.32915 to 2.29365, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.2953 - f1_weighted: 0.2676 - loss: 2.2534 - val_accuracy: 0.3466 - val_f1_weighted: 0.2954 - val_loss: 2.2936 - learning_rate: 0.0010
Epoch 20/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.2779 - f1_weighted: 0.2531 - loss: 2.2590
Epoch 20: val_loss improved from 2.29365 to 2.23561, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.3039 - f1_weighted: 0.2779 - loss: 2.1865 - val_accuracy: 0.3890 - val_f1_weighted: 0.3291 - val_loss: 2.2356 - learning_rate: 0.0010
Epoch 21/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.3286 - f1_weighted: 0.2994 - loss: 2.1063
Epoch 21: val_loss improved from 2.23561 to 2.12023, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.3312 - f1_weighted: 0.3053 - loss: 2.1153 - val_accuracy: 0.4190 - val_f1_weighted: 0.3689 - val_loss: 2.1202 - learning_rate: 0.0010
Epoch 22/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.3754 - f1_weighted: 0.3584 - loss: 1.9986
Epoch 22: val_loss improved from 2.12023 to 2.07041, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.3649 - f1_weighted: 0.3473 - loss: 2.0346 - val_accuracy: 0.4439 - val_f1_weighted: 0.3845 - val_loss: 2.0704 - learning_rate: 0.0010
Epoch 23/100
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.3765 - f1_weighted: 0.3503 - loss: 1.9751
Epoch 23: val_loss improved from 2.07041 to 1.93034, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.3959 - f1_weighted: 0.3699 - loss: 1.9450 - val_accuracy: 0.4564 - val_f1_weighted: 0.4033 - val_loss: 1.9303 - learning_rate: 0.0010
Epoch 24/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.4011 - f1_weighted: 0.3796 - loss: 1.8707
Epoch 24: val_loss improved from 1.93034 to 1.88606, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.4018 - f1_weighted: 0.3808 - loss: 1.8797 - val_accuracy: 0.4938 - val_f1_weighted: 0.4378 - val_loss: 1.8861 - learning_rate: 0.0010
Epoch 25/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.4256 - f1_weighted: 0.4096 - loss: 1.7683
Epoch 25: val_loss improved from 1.88606 to 1.81088, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.4275 - f1_weighted: 0.4115 - loss: 1.7743 - val_accuracy: 0.5212 - val_f1_weighted: 0.4742 - val_loss: 1.8109 - learning_rate: 0.0010
Epoch 26/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.4330 - f1_weighted: 0.4096 - loss: 1.7440
Epoch 26: val_loss improved from 1.81088 to 1.73422, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.4650 - f1_weighted: 0.4421 - loss: 1.6942 - val_accuracy: 0.5212 - val_f1_weighted: 0.4626 - val_loss: 1.7342 - learning_rate: 0.0010
Epoch 27/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.4537 - f1_weighted: 0.4221 - loss: 1.6954
Epoch 27: val_loss improved from 1.73422 to 1.64531, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.4628 - f1_weighted: 0.4401 - loss: 1.6660 - val_accuracy: 0.5586 - val_f1_weighted: 0.5092 - val_loss: 1.6453 - learning_rate: 0.0010
Epoch 28/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5022 - f1_weighted: 0.4749 - loss: 1.6226
Epoch 28: val_loss improved from 1.64531 to 1.62854, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.5072 - f1_weighted: 0.4799 - loss: 1.5884 - val_accuracy: 0.5337 - val_f1_weighted: 0.4843 - val_loss: 1.6285 - learning_rate: 0.0010
Epoch 29/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.4984 - f1_weighted: 0.4727 - loss: 1.6015
Epoch 29: val_loss improved from 1.62854 to 1.53982, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.5013 - f1_weighted: 0.4780 - loss: 1.5965 - val_accuracy: 0.5686 - val_f1_weighted: 0.5246 - val_loss: 1.5398 - learning_rate: 0.0010
Epoch 30/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5006 - f1_weighted: 0.4817 - loss: 1.4723
Epoch 30: val_loss improved from 1.53982 to 1.50576, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.5104 - f1_weighted: 0.4911 - loss: 1.4718 - val_accuracy: 0.5686 - val_f1_weighted: 0.5256 - val_loss: 1.5058 - learning_rate: 0.0010
Epoch 31/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5042 - f1_weighted: 0.4819 - loss: 1.4324
Epoch 31: val_loss improved from 1.50576 to 1.42138, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.5249 - f1_weighted: 0.5004 - loss: 1.4379 - val_accuracy: 0.6035 - val_f1_weighted: 0.5607 - val_loss: 1.4214 - learning_rate: 0.0010
Epoch 32/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5259 - f1_weighted: 0.5055 - loss: 1.3877
Epoch 32: val_loss improved from 1.42138 to 1.33340, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.5377 - f1_weighted: 0.5151 - loss: 1.3565 - val_accuracy: 0.6185 - val_f1_weighted: 0.5822 - val_loss: 1.3334 - learning_rate: 0.0010
Epoch 33/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.5903 - f1_weighted: 0.5671 - loss: 1.2686
Epoch 33: val_loss improved from 1.33340 to 1.27452, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.5757 - f1_weighted: 0.5484 - loss: 1.2956 - val_accuracy: 0.6259 - val_f1_weighted: 0.5921 - val_loss: 1.2745 - learning_rate: 0.0010
Epoch 34/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6066 - f1_weighted: 0.5781 - loss: 1.1869
Epoch 34: val_loss did not improve from 1.27452
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.6142 - f1_weighted: 0.5925 - loss: 1.1911 - val_accuracy: 0.6334 - val_f1_weighted: 0.5947 - val_loss: 1.2932 - learning_rate: 0.0010
Epoch 35/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6179 - f1_weighted: 0.5966 - loss: 1.2148
Epoch 35: val_loss improved from 1.27452 to 1.20521, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.6132 - f1_weighted: 0.5884 - loss: 1.1742 - val_accuracy: 0.6733 - val_f1_weighted: 0.6449 - val_loss: 1.2052 - learning_rate: 0.0010
Epoch 36/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6783 - f1_weighted: 0.6622 - loss: 1.0237
Epoch 36: val_loss improved from 1.20521 to 1.11824, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.6501 - f1_weighted: 0.6326 - loss: 1.0827 - val_accuracy: 0.6983 - val_f1_weighted: 0.6705 - val_loss: 1.1182 - learning_rate: 0.0010
Epoch 37/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6419 - f1_weighted: 0.6271 - loss: 1.0679
Epoch 37: val_loss improved from 1.11824 to 1.10220, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.6512 - f1_weighted: 0.6316 - loss: 1.0719 - val_accuracy: 0.6958 - val_f1_weighted: 0.6631 - val_loss: 1.1022 - learning_rate: 0.0010
Epoch 38/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6591 - f1_weighted: 0.6457 - loss: 0.9921
Epoch 38: val_loss improved from 1.10220 to 1.08224, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.6645 - f1_weighted: 0.6497 - loss: 1.0133 - val_accuracy: 0.7007 - val_f1_weighted: 0.6790 - val_loss: 1.0822 - learning_rate: 0.0010
Epoch 39/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6926 - f1_weighted: 0.6812 - loss: 0.9417
Epoch 39: val_loss did not improve from 1.08224
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.6816 - f1_weighted: 0.6684 - loss: 0.9856 - val_accuracy: 0.6783 - val_f1_weighted: 0.6643 - val_loss: 1.0879 - learning_rate: 0.0010
Epoch 40/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.6658 - f1_weighted: 0.6534 - loss: 0.9682
Epoch 40: val_loss improved from 1.08224 to 1.05114, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.6704 - f1_weighted: 0.6593 - loss: 0.9575 - val_accuracy: 0.7207 - val_f1_weighted: 0.6978 - val_loss: 1.0511 - learning_rate: 0.0010
Epoch 41/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7173 - f1_weighted: 0.7016 - loss: 0.8442
Epoch 41: val_loss improved from 1.05114 to 0.99561, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.7111 - f1_weighted: 0.6980 - loss: 0.8389 - val_accuracy: 0.7032 - val_f1_weighted: 0.6905 - val_loss: 0.9956 - learning_rate: 0.0010
Epoch 42/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7051 - f1_weighted: 0.6921 - loss: 0.8853
Epoch 42: val_loss improved from 0.99561 to 0.96587, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.7041 - f1_weighted: 0.6919 - loss: 0.8616 - val_accuracy: 0.7382 - val_f1_weighted: 0.7127 - val_loss: 0.9659 - learning_rate: 0.0010
Epoch 43/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7312 - f1_weighted: 0.7153 - loss: 0.8026
Epoch 43: val_loss did not improve from 0.96587
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7293 - f1_weighted: 0.7133 - loss: 0.8205 - val_accuracy: 0.7456 - val_f1_weighted: 0.7299 - val_loss: 0.9909 - learning_rate: 0.0010
Epoch 44/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7482 - f1_weighted: 0.7387 - loss: 0.7621
Epoch 44: val_loss improved from 0.96587 to 0.95330, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.7421 - f1_weighted: 0.7342 - loss: 0.7821 - val_accuracy: 0.7431 - val_f1_weighted: 0.7279 - val_loss: 0.9533 - learning_rate: 0.0010
Epoch 45/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7542 - f1_weighted: 0.7405 - loss: 0.7116
Epoch 45: val_loss improved from 0.95330 to 0.95289, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.7549 - f1_weighted: 0.7435 - loss: 0.7284 - val_accuracy: 0.7456 - val_f1_weighted: 0.7261 - val_loss: 0.9529 - learning_rate: 0.0010
Epoch 46/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7438 - f1_weighted: 0.7365 - loss: 0.7362
Epoch 46: val_loss improved from 0.95289 to 0.95190, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.7469 - f1_weighted: 0.7418 - loss: 0.7798 - val_accuracy: 0.7257 - val_f1_weighted: 0.7104 - val_loss: 0.9519 - learning_rate: 0.0010
Epoch 47/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7454 - f1_weighted: 0.7393 - loss: 0.7448
Epoch 47: val_loss improved from 0.95190 to 0.90453, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.7405 - f1_weighted: 0.7344 - loss: 0.7548 - val_accuracy: 0.7556 - val_f1_weighted: 0.7390 - val_loss: 0.9045 - learning_rate: 0.0010
Epoch 48/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7470 - f1_weighted: 0.7386 - loss: 0.7504
Epoch 48: val_loss did not improve from 0.90453
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7614 - f1_weighted: 0.7546 - loss: 0.7243 - val_accuracy: 0.7382 - val_f1_weighted: 0.7205 - val_loss: 0.9225 - learning_rate: 0.0010
Epoch 49/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7968 - f1_weighted: 0.7861 - loss: 0.6486
Epoch 49: val_loss improved from 0.90453 to 0.90285, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.7785 - f1_weighted: 0.7711 - loss: 0.6874 - val_accuracy: 0.7656 - val_f1_weighted: 0.7457 - val_loss: 0.9029 - learning_rate: 0.0010
Epoch 50/100
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.7980 - f1_weighted: 0.7905 - loss: 0.6180
Epoch 50: val_loss did not improve from 0.90285
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7849 - f1_weighted: 0.7768 - loss: 0.6402 - val_accuracy: 0.7481 - val_f1_weighted: 0.7281 - val_loss: 0.9759 - learning_rate: 0.0010
Epoch 51/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7737 - f1_weighted: 0.7715 - loss: 0.6766
Epoch 51: val_loss did not improve from 0.90285
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7865 - f1_weighted: 0.7821 - loss: 0.6547 - val_accuracy: 0.7756 - val_f1_weighted: 0.7603 - val_loss: 0.9034 - learning_rate: 0.0010
Epoch 52/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8182 - f1_weighted: 0.8135 - loss: 0.6462
Epoch 52: val_loss improved from 0.90285 to 0.84939, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.8117 - f1_weighted: 0.8070 - loss: 0.6346 - val_accuracy: 0.7781 - val_f1_weighted: 0.7653 - val_loss: 0.8494 - learning_rate: 0.0010
Epoch 53/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.7909 - f1_weighted: 0.7816 - loss: 0.6478
Epoch 53: val_loss did not improve from 0.84939
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.7999 - f1_weighted: 0.7954 - loss: 0.6497 - val_accuracy: 0.7880 - val_f1_weighted: 0.7753 - val_loss: 0.9142 - learning_rate: 0.0010
Epoch 54/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8159 - f1_weighted: 0.8132 - loss: 0.5739
Epoch 54: val_loss improved from 0.84939 to 0.81679, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.8175 - f1_weighted: 0.8151 - loss: 0.5878 - val_accuracy: 0.8030 - val_f1_weighted: 0.7906 - val_loss: 0.8168 - learning_rate: 0.0010
Epoch 55/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8364 - f1_weighted: 0.8331 - loss: 0.5583
Epoch 55: val_loss did not improve from 0.81679
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8331 - f1_weighted: 0.8284 - loss: 0.5780 - val_accuracy: 0.7855 - val_f1_weighted: 0.7699 - val_loss: 0.8619 - learning_rate: 0.0010
Epoch 56/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8459 - f1_weighted: 0.8433 - loss: 0.5029
Epoch 56: val_loss did not improve from 0.81679
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8341 - f1_weighted: 0.8309 - loss: 0.5303 - val_accuracy: 0.7880 - val_f1_weighted: 0.7718 - val_loss: 0.8598 - learning_rate: 0.0010
Epoch 57/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8411 - f1_weighted: 0.8378 - loss: 0.5283
Epoch 57: val_loss improved from 0.81679 to 0.80935, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.8390 - f1_weighted: 0.8364 - loss: 0.5076 - val_accuracy: 0.8055 - val_f1_weighted: 0.7907 - val_loss: 0.8093 - learning_rate: 0.0010
Epoch 58/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8594 - f1_weighted: 0.8578 - loss: 0.4886
Epoch 58: val_loss did not improve from 0.80935
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8555 - f1_weighted: 0.8539 - loss: 0.4974 - val_accuracy: 0.7955 - val_f1_weighted: 0.7799 - val_loss: 0.8325 - learning_rate: 0.0010
Epoch 59/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8610 - f1_weighted: 0.8565 - loss: 0.4175
Epoch 59: val_loss improved from 0.80935 to 0.79979, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.8502 - f1_weighted: 0.8464 - loss: 0.4691 - val_accuracy: 0.8030 - val_f1_weighted: 0.7966 - val_loss: 0.7998 - learning_rate: 0.0010
Epoch 60/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8486 - f1_weighted: 0.8470 - loss: 0.4972
Epoch 60: val_loss did not improve from 0.79979
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8459 - f1_weighted: 0.8437 - loss: 0.5370 - val_accuracy: 0.7855 - val_f1_weighted: 0.7720 - val_loss: 0.8580 - learning_rate: 0.0010
Epoch 61/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8521 - f1_weighted: 0.8476 - loss: 0.4766
Epoch 61: val_loss did not improve from 0.79979
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8625 - f1_weighted: 0.8598 - loss: 0.4463 - val_accuracy: 0.8105 - val_f1_weighted: 0.8005 - val_loss: 0.8180 - learning_rate: 0.0010
Epoch 62/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8671 - f1_weighted: 0.8649 - loss: 0.4581
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 62: val_loss did not improve from 0.79979
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8694 - f1_weighted: 0.8672 - loss: 0.4478 - val_accuracy: 0.7955 - val_f1_weighted: 0.7835 - val_loss: 0.8511 - learning_rate: 0.0010
Epoch 63/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8803 - f1_weighted: 0.8781 - loss: 0.4021
Epoch 63: val_loss did not improve from 0.79979
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8839 - f1_weighted: 0.8818 - loss: 0.4054 - val_accuracy: 0.8130 - val_f1_weighted: 0.8038 - val_loss: 0.8115 - learning_rate: 5.0000e-04
Epoch 64/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8876 - f1_weighted: 0.8859 - loss: 0.3761
Epoch 64: val_loss improved from 0.79979 to 0.79755, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.8855 - f1_weighted: 0.8847 - loss: 0.3989 - val_accuracy: 0.8080 - val_f1_weighted: 0.7986 - val_loss: 0.7976 - learning_rate: 5.0000e-04
Epoch 65/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8947 - f1_weighted: 0.8913 - loss: 0.3664
Epoch 65: val_loss did not improve from 0.79755
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8909 - f1_weighted: 0.8894 - loss: 0.3677 - val_accuracy: 0.8105 - val_f1_weighted: 0.8021 - val_loss: 0.8016 - learning_rate: 5.0000e-04
Epoch 66/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9010 - f1_weighted: 0.9004 - loss: 0.3402
Epoch 66: val_loss did not improve from 0.79755
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.8978 - f1_weighted: 0.8969 - loss: 0.3416 - val_accuracy: 0.8080 - val_f1_weighted: 0.7998 - val_loss: 0.8240 - learning_rate: 5.0000e-04
Epoch 67/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8978 - f1_weighted: 0.8960 - loss: 0.3475
Epoch 67: val_loss improved from 0.79755 to 0.79371, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.9005 - f1_weighted: 0.8995 - loss: 0.3340 - val_accuracy: 0.8204 - val_f1_weighted: 0.8129 - val_loss: 0.7937 - learning_rate: 5.0000e-04
Epoch 68/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.8993 - f1_weighted: 0.8978 - loss: 0.3267
Epoch 68: val_loss improved from 0.79371 to 0.79203, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.8999 - f1_weighted: 0.8991 - loss: 0.3214 - val_accuracy: 0.8229 - val_f1_weighted: 0.8164 - val_loss: 0.7920 - learning_rate: 5.0000e-04
Epoch 69/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9014 - f1_weighted: 0.9009 - loss: 0.3549
Epoch 69: val_loss did not improve from 0.79203
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9037 - f1_weighted: 0.9032 - loss: 0.3369 - val_accuracy: 0.8204 - val_f1_weighted: 0.8129 - val_loss: 0.8075 - learning_rate: 5.0000e-04
Epoch 70/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9086 - f1_weighted: 0.9078 - loss: 0.3098
Epoch 70: val_loss improved from 0.79203 to 0.79195, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.9101 - f1_weighted: 0.9091 - loss: 0.2958 - val_accuracy: 0.8254 - val_f1_weighted: 0.8183 - val_loss: 0.7919 - learning_rate: 5.0000e-04
Epoch 71/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9170 - f1_weighted: 0.9162 - loss: 0.2533
Epoch 71: val_loss improved from 0.79195 to 0.79091, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.9106 - f1_weighted: 0.9101 - loss: 0.2699 - val_accuracy: 0.8204 - val_f1_weighted: 0.8146 - val_loss: 0.7909 - learning_rate: 5.0000e-04
Epoch 72/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.8958 - f1_weighted: 0.8943 - loss: 0.3171
Epoch 72: val_loss did not improve from 0.79091
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - accuracy: 0.9069 - f1_weighted: 0.9061 - loss: 0.2935 - val_accuracy: 0.8155 - val_f1_weighted: 0.8064 - val_loss: 0.8093 - learning_rate: 5.0000e-04
Epoch 73/100
<span class=" -Color -Color-Bold">28/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9093 - f1_weighted: 0.9092 - loss: 0.2788
Epoch 73: val_loss improved from 0.79091 to 0.73843, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.9101 - f1_weighted: 0.9099 - loss: 0.2997 - val_accuracy: 0.8304 - val_f1_weighted: 0.8265 - val_loss: 0.7384 - learning_rate: 5.0000e-04
Epoch 74/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9149 - f1_weighted: 0.9151 - loss: 0.2852
Epoch 74: val_loss improved from 0.73843 to 0.72248, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.9213 - f1_weighted: 0.9217 - loss: 0.2698 - val_accuracy: 0.8354 - val_f1_weighted: 0.8316 - val_loss: 0.7225 - learning_rate: 5.0000e-04
Epoch 75/100
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.9175 - f1_weighted: 0.9181 - loss: 0.2773
Epoch 75: val_loss did not improve from 0.72248
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9112 - f1_weighted: 0.9112 - loss: 0.2895 - val_accuracy: 0.8329 - val_f1_weighted: 0.8288 - val_loss: 0.7693 - learning_rate: 5.0000e-04
Epoch 76/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9238 - f1_weighted: 0.9233 - loss: 0.2418
Epoch 76: val_loss did not improve from 0.72248
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9197 - f1_weighted: 0.9194 - loss: 0.2443 - val_accuracy: 0.8429 - val_f1_weighted: 0.8396 - val_loss: 0.7651 - learning_rate: 5.0000e-04
Epoch 77/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9175 - f1_weighted: 0.9172 - loss: 0.2648
Epoch 77: val_loss improved from 0.72248 to 0.71575, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 18ms/step - accuracy: 0.9149 - f1_weighted: 0.9142 - loss: 0.2674 - val_accuracy: 0.8404 - val_f1_weighted: 0.8366 - val_loss: 0.7158 - learning_rate: 5.0000e-04
Epoch 78/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9272 - f1_weighted: 0.9267 - loss: 0.2348
Epoch 78: val_loss did not improve from 0.71575
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9288 - f1_weighted: 0.9288 - loss: 0.2335 - val_accuracy: 0.8354 - val_f1_weighted: 0.8284 - val_loss: 0.7227 - learning_rate: 5.0000e-04
Epoch 79/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9288 - f1_weighted: 0.9291 - loss: 0.2291
Epoch 79: val_loss did not improve from 0.71575
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9272 - f1_weighted: 0.9272 - loss: 0.2254 - val_accuracy: 0.8329 - val_f1_weighted: 0.8264 - val_loss: 0.7839 - learning_rate: 5.0000e-04
Epoch 80/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9286 - f1_weighted: 0.9277 - loss: 0.2617
Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.

Epoch 80: val_loss did not improve from 0.71575
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9240 - f1_weighted: 0.9236 - loss: 0.2587 - val_accuracy: 0.8529 - val_f1_weighted: 0.8482 - val_loss: 0.7260 - learning_rate: 5.0000e-04
Epoch 81/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9319 - f1_weighted: 0.9317 - loss: 0.2282
Epoch 81: val_loss did not improve from 0.71575
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9331 - f1_weighted: 0.9328 - loss: 0.2232 - val_accuracy: 0.8329 - val_f1_weighted: 0.8260 - val_loss: 0.7325 - learning_rate: 2.5000e-04
Epoch 82/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9486 - f1_weighted: 0.9482 - loss: 0.1805
Epoch 82: val_loss improved from 0.71575 to 0.71418, saving model to results_cnn1d/best_cnn1d_model.keras
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 19ms/step - accuracy: 0.9395 - f1_weighted: 0.9394 - loss: 0.1986 - val_accuracy: 0.8404 - val_f1_weighted: 0.8355 - val_loss: 0.7142 - learning_rate: 2.5000e-04
Epoch 83/100
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 12ms/step - accuracy: 0.9342 - f1_weighted: 0.9335 - loss: 0.2299
Epoch 83: val_loss did not improve from 0.71418
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9337 - f1_weighted: 0.9335 - loss: 0.2362 - val_accuracy: 0.8529 - val_f1_weighted: 0.8488 - val_loss: 0.7239 - learning_rate: 2.5000e-04
Epoch 84/100
<span class=" -Color -Color-Bold">29/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9390 - f1_weighted: 0.9391 - loss: 0.2022
Epoch 84: val_loss did not improve from 0.71418
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9353 - f1_weighted: 0.9352 - loss: 0.2117 - val_accuracy: 0.8579 - val_f1_weighted: 0.8536 - val_loss: 0.7264 - learning_rate: 2.5000e-04
Epoch 85/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9532 - f1_weighted: 0.9530 - loss: 0.1708
Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.

Epoch 85: val_loss did not improve from 0.71418
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9524 - f1_weighted: 0.9522 - loss: 0.1748 - val_accuracy: 0.8554 - val_f1_weighted: 0.8523 - val_loss: 0.7445 - learning_rate: 2.5000e-04
Epoch 86/100
<span class=" -Color -Color-Bold">26/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9545 - f1_weighted: 0.9538 - loss: 0.1630
Epoch 86: val_loss did not improve from 0.71418
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9481 - f1_weighted: 0.9476 - loss: 0.1778 - val_accuracy: 0.8579 - val_f1_weighted: 0.8539 - val_loss: 0.7302 - learning_rate: 1.2500e-04
Epoch 87/100
<span class=" -Color -Color-Bold">27/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━</span><span class=" -Color -Color-White">━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - accuracy: 0.9492 - f1_weighted: 0.9490 - loss: 0.1578
Epoch 87: val_loss did not improve from 0.71418
<span class=" -Color -Color-Bold">30/30</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - accuracy: 0.9497 - f1_weighted: 0.9495 - loss: 0.1683 - val_accuracy: 0.8554 - val_f1_weighted: 0.8510 - val_loss: 0.7441 - learning_rate: 1.2500e-04
Epoch 87: early stopping
Restoring model weights from the end of the best epoch: 82.

 Entrenamiento completado!
   - Tiempo: 67.64s (1.13 min)
   - Epochs: 87/100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graficar_historial_entrenamiento</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s2">&quot;CNN-1D&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Generando gráficas de entrenamiento para CNN-1D...
</pre></div>
</div>
<img alt="_images/1b2e871e2a382ac7802b33063399bb1b7b8887a7391540828d108243c0cff692.png" src="_images/1b2e871e2a382ac7802b33063399bb1b7b8887a7391540828d108243c0cff692.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Gráficas guardadas en: results_cnn1d/cnn-1d_training_history.png
</pre></div>
</div>
</div>
</div>
<p>El entrenamiento del modelo <strong>CNN-1D</strong> presenta un comportamiento estable y coherente a lo largo de las épocas. El <strong>train loss</strong> disminuye de forma continua, lo que indica que el modelo está aprendiendo patrones relevantes del corpus. El <strong>Validation Loss</strong> también desciende en las primeras etapas, pero a partir de la <strong>época 40</strong> deja de mejorar significativamente, señalando el inicio del <strong>sobreajuste</strong>. Gracias a las reducciones automáticas del <em>learning rate</em>, la pérdida de validación alcanzó un <strong>mínimo de 0.7142</strong>, mostrando una ligera recuperación y mayor estabilidad hacia el final del entrenamiento.</p>
<p>En cuanto al <strong>F1-Score ponderado</strong>, se observa un progreso sostenido en ambas curvas. El <strong>F1 ponderado de entrenamiento</strong> aumenta hasta aproximadamente <strong>0.93</strong>, mientras que el <strong>F1 ponderado de validación</strong> se estabiliza alrededor de <strong>0.80–0.85</strong>, lo que evidencia un rendimiento sólido y una adecuada capacidad de generalización, a pesar del leve sobreajuste. La estabilidad de esta métrica confirma que la <strong>CNN-1D</strong> maneja correctamente la variabilidad entre clases y mantiene un buen equilibrio entre aprendizaje y generalización.</p>
<p>Calculamos el rendimiento final sobre el conjunto de <em>Test</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -----------------------------</span>
<span class="c1"># 7. Evaluación</span>
<span class="c1"># -----------------------------</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EVALUACIÓN EN TEST&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">y_pred_probs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
    <span class="s1">&#39;Precision (weighted)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Precision (macro)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (weighted)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (macro)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (weighted)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (macro)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">num_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test_indices</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_probs</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;ROC-AUC (macro)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;ROC-AUC (macro)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">30s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
EVALUACIÓN EN TEST
======================================================================
Accuracy                      : 0.8778
Precision (weighted)          : 0.8847
Precision (macro)             : 0.8834
Recall (weighted)             : 0.8778
Recall (macro)                : 0.8755
F1-Score (weighted)           : 0.8770
F1-Score (macro)              : 0.8750
ROC-AUC (macro)               : 0.9884
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>CNN-1D</strong>, seleccionado según el mejor <span class="math notranslate nohighlight">\(F1\)</span>-<span class="math notranslate nohighlight">\(Score_{Weighted}\)</span> en el conjunto de validación, fue evaluado sobre el conjunto de <strong>prueba</strong>, el cual conserva la distribución original y desbalanceada de clases.</p>
<section id="id1">
<h3>Métricas de rendimiento en el conjunto de prueba<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Métrica</strong></p></th>
<th class="head"><p><strong>Valor</strong></p></th>
<th class="head"><p><strong>Observación Técnica</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Accuracy (Exactitud)</p></td>
<td><p>87.78 %</p></td>
<td><p>Alta tasa de aciertos globales, con buena estabilidad en todas las clases.</p></td>
</tr>
<tr class="row-odd"><td><p>F1-Score Weighted</p></td>
<td><p>87.70 %</p></td>
<td><p>Métrica clave: refleja un rendimiento sólido ponderado por el soporte real de las clases.</p></td>
</tr>
<tr class="row-even"><td><p>F1-Score Macro</p></td>
<td><p>87.50 %</p></td>
<td><p>Desempeño equilibrado entre clases, lo que indica buena generalización.</p></td>
</tr>
<tr class="row-odd"><td><p>Precision Weighted</p></td>
<td><p>88.10 %</p></td>
<td><p>Alta fiabilidad en las predicciones positivas.</p></td>
</tr>
<tr class="row-even"><td><p>Recall Weighted</p></td>
<td><p>87.78 %</p></td>
<td><p>Elevada capacidad para detectar instancias verdaderas.</p></td>
</tr>
<tr class="row-odd"><td><p>ROC-AUC Macro</p></td>
<td><p>98.84 %</p></td>
<td><p>Excelente capacidad discriminativa entre las clases.</p></td>
</tr>
</tbody>
</table>
</div>
<p>El modelo demuestra una <strong>generalización sobresaliente</strong>, alcanzando un <span class="math notranslate nohighlight">\(F1\)</span>-<span class="math notranslate nohighlight">\(Score_{Weighted}\)</span> de <strong>87.70 %</strong> en el conjunto de prueba, muy cercano al valor máximo obtenido durante la validación.</p>
<ul class="simple">
<li><p><strong>Balance y robustez:</strong> La concordancia entre los valores de <span class="math notranslate nohighlight">\(F1_{Weighted}\)</span> (87.70 %) y <span class="math notranslate nohighlight">\(F1_{Macro}\)</span> (87.50 %) confirma la efectividad del entrenamiento y de la estrategia de <strong>pérdida ponderada</strong>, logrando un rendimiento casi uniforme entre las clases.</p></li>
<li><p><strong>Capacidad discriminativa:</strong> El <span class="math notranslate nohighlight">\(ROC\ AUC_{Macro}\)</span> de <strong>98.84 %</strong> evidencia una excelente separación entre categorías y la solidez de las <strong>representaciones semánticas</strong> aprendidas por la CNN-1D.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">y_test_indices</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">y_pred</span>

<span class="c1"># Mostrar matriz con paleta morada estándar</span>
<span class="n">mostrar_matriz_confusion</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">category_map</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Matriz de Confusión - CNN-1D (GloVe)</span><span class="se">\n</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4dd297284389b1bd54dde4aa8a8a5aea50ed83b0039307daf9c33b5e49437657.png" src="_images/4dd297284389b1bd54dde4aa8a8a5aea50ed83b0039307daf9c33b5e49437657.png" />
</div>
</div>
<p>La matriz de confusipon del modelo <strong>CNN-1D (GloVe)</strong> muestra un rendimiento general sólido con una accuracy del <strong>87.78%</strong>, el modelo es altamente efectivo en la tarea de clasificación, logrando una identificación casi perfecta en categorías bien definidas. Los errores de clasificación son aislados y dispersos en la mayoría de las clases, y solo la clase <strong>Digital-Media</strong> requiere una revisión más profunda en el etiquetado o la representación de sus datos. La fortaleza en la diagonal principal de la matriz es la prueba empírica de que el modelo ha aprendido con éxito a distinguir las representaciones semánticas del texto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_curvas_roc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">y_test_indices</span><span class="p">,</span>
    <span class="n">y_prob</span><span class="o">=</span><span class="n">y_pred_probs</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="s2">&quot;Curvas ROC–AUC por clase - CNN-1D (GloVe)&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4d1718e944e834f5af783289c4702f43246010c1350366ded04c691c0eb8fecd.png" src="_images/4d1718e944e834f5af783289c4702f43246010c1350366ded04c691c0eb8fecd.png" />
</div>
</div>
<p>Las <strong>Curvas ROC-AUC por clase</strong> son la evidencia más fuerte del éxito del modelo.</p>
<ul class="simple">
<li><p><strong>Puntuaciones Altas:</strong> La mayoría de las clases (10 de 24) alcanzan un <strong>AUC de 1.00</strong>, y la mayoría de las restantes tienen un <strong>AUC entre 0.96 y 0.99</strong>.</p></li>
<li><p><strong>Conclusión:</strong> Un <strong>ROC-AUC macro de 0.9884</strong> y estas curvas confirman que el modelo <strong>CNN-1D (GloVe)</strong> no solo predice bien, sino que sus representaciones latentes tienen una <strong>separación entre categorías excelente</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analizar_errores</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">y_test_indices</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">category_map</span><span class="p">,</span>
    <span class="n">nombre_modelo</span><span class="o">=</span><span class="s2">&quot;CNN-1D (GloVe)&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
 RESUMEN DE ERRORES - CNN-1D (GloVe)
============================================================
 Predicciones correctas: 352
 Predicciones incorrectas: 49
 Total de ejemplos: 401
 Accuracy: 87.78%
 Tasa de error: 12.22%
============================================================

 ERRORES POR CLASE:
------------------------------------------------------------
ACCOUNTANT               : 2/18 errores (88.89% accuracy)
ADVOCATE                 : 3/18 errores (83.33% accuracy)
AGRICULTURE              : 3/15 errores (80.00% accuracy)
APPAREL                  : 5/15 errores (66.67% accuracy)
ARTS                     : 4/15 errores (73.33% accuracy)
AUTOMOBILE               : 0/15 errores (100.00% accuracy)
AVIATION                 : 3/18 errores (83.33% accuracy)
BANKING                  : 5/17 errores (70.59% accuracy)
BPO                      : 0/15 errores (100.00% accuracy)
BUSINESS-DEVELOPMENT     : 0/18 errores (100.00% accuracy)
CHEF                     : 3/18 errores (83.33% accuracy)
CONSTRUCTION             : 2/17 errores (88.24% accuracy)
CONSULTANT               : 2/17 errores (88.24% accuracy)
DESIGNER                 : 0/16 errores (100.00% accuracy)
DIGITAL-MEDIA            : 5/14 errores (64.29% accuracy)
ENGINEERING              : 1/18 errores (94.44% accuracy)
FINANCE                  : 0/18 errores (100.00% accuracy)
FITNESS                  : 4/18 errores (77.78% accuracy)
HEALTHCARE               : 2/17 errores (88.24% accuracy)
HR                       : 0/17 errores (100.00% accuracy)
INFORMATION-TECHNOLOGY   : 0/18 errores (100.00% accuracy)
PUBLIC-RELATIONS         : 2/17 errores (88.24% accuracy)
SALES                    : 3/17 errores (82.35% accuracy)
TEACHER                  : 0/15 errores (100.00% accuracy)

 CONFUSIONES MÁS COMUNES:
------------------------------------------------------------
BANKING → CONSULTANT: 4 veces (8.2% de errores)
SALES → APPAREL: 2 veces (4.1% de errores)
APPAREL → DESIGNER: 2 veces (4.1% de errores)
DIGITAL-MEDIA → ARTS: 2 veces (4.1% de errores)
ADVOCATE → SALES: 1 veces (2.0% de errores)
ADVOCATE → BANKING: 1 veces (2.0% de errores)
CONSULTANT → FINANCE: 1 veces (2.0% de errores)
DIGITAL-MEDIA → DESIGNER: 1 veces (2.0% de errores)
AVIATION → AGRICULTURE: 1 veces (2.0% de errores)
FITNESS → HEALTHCARE: 1 veces (2.0% de errores)
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>CNN-1D (GloVe)</strong> muestra un rendimiento perfecto (<strong>100% de accuracy</strong>) en 8 de las 24 clases, incluyendo <strong>BUSINESS-DEVELOPMENT, FINANCE, HR, BPO, INFORMATION-TECHNOLOGY, AUTOMOBILE, DESIGNER</strong> y <strong>TEACHER</strong>, lo que confirma su robustez en estas áreas. La mayor parte de los errores (<strong>12.22%</strong>) se concentra en unas pocas clases, especialmente <strong>APPAREL, DIGITAL-MEDIA y BANKING</strong>, donde se observan confusiones semánticas significativas: BANKING a veces se clasifica como CONSULTANT, APPAREL como DESIGNER y DIGITAL-MEDIA como ARTS, reflejando solapamiento en el lenguaje y contextos similares.</p>
<p>Las clases con desempeño perfecto tienen patrones lingüísticos claros y fácilmente distinguibles, mientras que las clases con errores comparten vocabulario o descripciones ambiguas. Esto indica que la <strong>CNN-1D</strong>, aunque eficaz en patrones locales, podría beneficiarse de embeddings contextualizados (como <strong>DistilBERT</strong> o <strong>RoBERTa</strong>) o mecanismos de atención para mejorar la diferenciación entre clases cercanas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10. Guardar</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Guardando...&quot;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;cnn1d_model_final.keras&#39;</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;cnn1d_predictions.npy&#39;</span><span class="p">),</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;cnn1d_probabilities.npy&#39;</span><span class="p">),</span> <span class="n">y_pred_probs</span><span class="p">)</span>

<span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">metrics</span><span class="p">])</span>
<span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;CNN-1D_GloVe&#39;</span>
<span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;training_time_seconds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_time</span>
<span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;epochs_trained&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epochs_trained</span>
<span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;has_pretrained_embeddings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">PARAMS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">df_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;param_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

<span class="n">df_metrics</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;cnn1d_metrics.csv&#39;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Guardando...
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="modelo-4-tf-idf-xgboost-gpu-version">
<h2>Modelo 4: TF-IDF + XGBoost (GPU version)<a class="headerlink" href="#modelo-4-tf-idf-xgboost-gpu-version" title="Permalink to this heading">#</a></h2>
<p><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong> es una representación vectorial eficiente para el procesamiento de lenguaje natural (NLP) que pondera la importancia de un término dentro de un documento en relación con su frecuencia en todo el corpus. Esto permite que el modelo <strong>XGBoost</strong> se enfoque en los términos más discriminantes para la clasificación multiclase. Además, la naturaleza inherentemente dispersa de los vectores TF-IDF hace indispensable el uso de formatos optimizados (<code class="docutils literal notranslate"><span class="pre">.npz</span></code>, <code class="docutils literal notranslate"><span class="pre">xgb.DMatrix</span></code>) para manejar miles de características de texto sin agotar la memoria, una sinergia perfecta con la capacidad de <strong>XGBoost</strong> para gestionar entradas dispersas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.sparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_npz</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">xgb</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost.callback</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingCallback</span>
</pre></div>
</div>
</div>
</div>
<p>Se cargan los conjuntos de <strong>entrenamiento</strong>, <strong>validación</strong> y <strong>prueba</strong> en formato disperso (<code class="docutils literal notranslate"><span class="pre">.npz</span></code>) para las características <strong>TF-IDF</strong>, y en formato <strong>NumPy</strong> para las etiquetas. Esta estructura permite manejar eficientemente <strong>vectores de alta dimensionalidad</strong> sin consumir memoria innecesaria. Las etiquetas se <strong>binarizan</strong> para facilitar el cálculo de métricas como <strong>ROC-AUC multiclase</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Cargar datos</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_npz</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_train_X.npz&quot;</span><span class="p">)</span>
<span class="n">X_val</span>   <span class="o">=</span> <span class="n">load_npz</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_val_X.npz&quot;</span><span class="p">)</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">load_npz</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_test_X.npz&quot;</span><span class="p">)</span>

<span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_train_y.npy&quot;</span><span class="p">)</span>
<span class="n">Y_val</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_val_y.npy&quot;</span><span class="p">)</span>
<span class="n">Y_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;processed_data/tfidf_xgboost_test_y.npy&quot;</span><span class="p">)</span>

<span class="n">labels_bin_val</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">Y_val</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>El modelo se configura con un conjunto de <strong>hiperparámetros regularizados</strong> y optimizados para un <strong>entrenamiento acelerado en GPU</strong>. Se utiliza <code class="docutils literal notranslate"><span class="pre">device</span> <span class="pre">=</span> <span class="pre">cuda</span></code> junto con <code class="docutils literal notranslate"><span class="pre">tree_method</span> <span class="pre">=</span> <span class="pre">hist</span></code> para acelerar el proceso, mientras que <code class="docutils literal notranslate"><span class="pre">objective</span> <span class="pre">=</span> <span class="pre">multi:softprob</span></code> y <code class="docutils literal notranslate"><span class="pre">eval_metric</span> <span class="pre">=</span> <span class="pre">mlogloss</span></code> permiten abordar la <strong>clasificación multiclase</strong> y evaluar la pérdida logarítmica correspondiente.</p>
<p>La <strong>regularización L1 y L2</strong> se establece con <code class="docutils literal notranslate"><span class="pre">reg_alpha</span> <span class="pre">=</span> <span class="pre">5.0</span></code> y <code class="docutils literal notranslate"><span class="pre">reg_lambda</span> <span class="pre">=</span> <span class="pre">5.0</span></code> para minimizar el sobreajuste, y la estructura del modelo se ajusta con <code class="docutils literal notranslate"><span class="pre">max_depth</span> <span class="pre">=</span> <span class="pre">3</span></code> y <code class="docutils literal notranslate"><span class="pre">min_child_weight</span> <span class="pre">=</span> <span class="pre">15</span></code> para limitar la complejidad de los árboles. Además, se aplica <strong>submuestreo</strong> (<code class="docutils literal notranslate"><span class="pre">subsample</span> <span class="pre">=</span> <span class="pre">0.6</span></code>, <code class="docutils literal notranslate"><span class="pre">colsample_bytree</span> <span class="pre">=</span> <span class="pre">0.5</span></code>) sobre filas y columnas para mejorar la robustez y diversidad del ensemble.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parámetros</span>
<span class="n">params_regularized</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tree_method&quot;</span><span class="p">:</span> <span class="s2">&quot;hist&quot;</span><span class="p">,</span>
    <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="s2">&quot;objective&quot;</span><span class="p">:</span> <span class="s2">&quot;multi:softprob&quot;</span><span class="p">,</span>
    <span class="s2">&quot;num_class&quot;</span><span class="p">:</span> <span class="n">NUM_CLASSES</span><span class="p">,</span>
    <span class="s2">&quot;eval_metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mlogloss&quot;</span><span class="p">,</span>
    
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>        
    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>               
    <span class="s2">&quot;min_child_weight&quot;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>        
    <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>             
    <span class="s2">&quot;colsample_bytree&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>      
    <span class="s2">&quot;colsample_bylevel&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>     
    
    <span class="s2">&quot;reg_alpha&quot;</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>             
    <span class="s2">&quot;reg_lambda&quot;</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>            
    
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>                 
    <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="mi">42</span>
<span class="p">}</span>


<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">dval</span>   <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Y_val</span><span class="p">)</span>
<span class="n">dtest</span>  <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Callback Personalizado (MetricsCallback):</strong><br />
Dado que XGBoost no calcula métricas secundarias en cada iteración, se desarrolla un callback que, tras cada ronda de boosting, predice las etiquetas en los conjuntos de entrenamiento y validación, calculando <strong>Accuracy</strong>, <strong>F1-Score ponderado</strong> y <strong>mlogloss</strong>.<br />
Estos resultados se almacenan en una estructura histórica (<code class="docutils literal notranslate"><span class="pre">self.history</span></code> / <code class="docutils literal notranslate"><span class="pre">df_history</span></code>) para su posterior análisis y visualización de curvas de aprendizaje, permitiendo detectar de forma precisa signos de overfitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Callbacks</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MetricsCallback</span><span class="p">(</span><span class="n">TrainingCallback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">dval</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">,</span> <span class="n">labels_bin_val</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtrain</span> <span class="o">=</span> <span class="n">dtrain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dval</span> <span class="o">=</span> <span class="n">dval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">Y_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y_val</span> <span class="o">=</span> <span class="n">Y_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_bin_val</span> <span class="o">=</span> <span class="n">labels_bin_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">after_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">evals_log</span><span class="p">):</span>
       
        <span class="n">probs_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtrain</span><span class="p">)</span>
        <span class="n">preds_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs_train</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

      
        <span class="n">probs_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dval</span><span class="p">)</span>
        <span class="n">preds_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs_val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

 
        <span class="n">acc_train</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">preds_train</span><span class="p">)</span>
        <span class="n">f1_w_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">preds_train</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

       
        <span class="n">acc_val</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y_val</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
        <span class="n">f1_w_val</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y_val</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

   
        <span class="n">logloss_val</span> <span class="o">=</span> <span class="n">evals_log</span><span class="p">[</span><span class="s1">&#39;eval&#39;</span><span class="p">][</span><span class="s1">&#39;mlogloss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;eval&#39;</span> <span class="ow">in</span> <span class="n">evals_log</span> <span class="ow">and</span> <span class="s1">&#39;mlogloss&#39;</span> <span class="ow">in</span> <span class="n">evals_log</span><span class="p">[</span><span class="s1">&#39;eval&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;Epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">&#39;Train Loss&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>  
            <span class="s1">&#39;Val Loss&#39;</span><span class="p">:</span> <span class="n">logloss_val</span><span class="p">,</span>
            <span class="s1">&#39;Train Accuracy&#39;</span><span class="p">:</span> <span class="n">acc_train</span><span class="p">,</span>
            <span class="s1">&#39;Val Accuracy&#39;</span><span class="p">:</span> <span class="n">acc_val</span><span class="p">,</span>
            <span class="s1">&#39;Train F1 Weighted&#39;</span><span class="p">:</span> <span class="n">f1_w_train</span><span class="p">,</span>
            <span class="s1">&#39;Val F1 Weighted&#39;</span><span class="p">:</span> <span class="n">f1_w_val</span>
        <span class="p">})</span>

        <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<p>Procedemos al entrenamiento del modelo, donde se aplica <code class="docutils literal notranslate"><span class="pre">early_stopping_rounds</span> <span class="pre">=</span> <span class="pre">10</span></code>, deteniéndolo cuando la métrica de validación (<strong>mlogloss</strong>) no mejora durante 10 iteraciones consecutivas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Entrenamiento</span>
<span class="n">metrics_cb</span> <span class="o">=</span> <span class="n">MetricsCallback</span><span class="p">(</span><span class="n">dtrain</span><span class="p">,</span> <span class="n">dval</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">,</span> <span class="n">labels_bin_val</span><span class="p">)</span>

<span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params_regularized</span><span class="p">,</span>
    <span class="n">dtrain</span><span class="o">=</span><span class="n">dtrain</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
    <span class="n">evals</span><span class="o">=</span><span class="p">[(</span><span class="n">dval</span><span class="p">,</span> <span class="s2">&quot;eval&quot;</span><span class="p">)],</span>
    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">metrics_cb</span><span class="p">],</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">df_history</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">metrics_cb</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Verificar sobreajuste</span>
<span class="n">last_epoch</span> <span class="o">=</span> <span class="n">df_history</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gap_accuracy</span> <span class="o">=</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Val Accuracy&#39;</span><span class="p">]</span>
<span class="n">gap_f1</span> <span class="o">=</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Train F1 Weighted&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Val F1 Weighted&#39;</span><span class="p">]</span>
<span class="n">gap_loss</span> <span class="o">=</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> GAP Train-Val (última época </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">last_epoch</span><span class="p">[</span><span class="s1">&#39;Epoch&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   • Accuracy Gap:  </span><span class="si">{</span><span class="n">gap_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">gap_accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   • F1 Gap:        </span><span class="si">{</span><span class="n">gap_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">gap_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

<span class="c1"># Graficar</span>
<span class="n">graficar_historial_xgboost</span><span class="p">(</span><span class="n">df_history</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;results_xgb&#39;</span><span class="p">,</span> <span class="n">nombre_modelo</span><span class="o">=</span><span class="s1">&#39;XGBoost_Regularized&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> GAP Train-Val (última época 3863):
   • Accuracy Gap:  0.0646 (6.46%)
   • F1 Gap:        0.0702 (7.02%)

 Generando gráficas de entrenamiento para XGBoost_Regularized...
</pre></div>
</div>
<img alt="_images/5231a6ada4156e79c11aec62ce1a9cb5a98bbd302963be25156f71d18e1efb60.png" src="_images/5231a6ada4156e79c11aec62ce1a9cb5a98bbd302963be25156f71d18e1efb60.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Gráficas guardadas en: results_xgb/xgboost_regularized_training_history.png
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>TF-IDF + XGBoost</strong> muestra un aprendizaje efectivo y una regularización adecuada. La <strong>curva de pérdida</strong> indica que la validación loss desciende suavemente hasta la época 3000 y luego converge, activando el Early Stopping en la época 3863, sin signos de sobreajuste extremo. La <strong>curva de F1-Score ponderado</strong> evidencia una ganancia rápida en las primeras 1000 épocas, alcanzando un F1 de ~0.80 en entrenamiento y ~0.73 en validación, con un <strong>gap estable de 6-7%</strong>, señalando un sobreajuste leve a moderado.</p>
<p>A pesar de este gap, la pérdida de validación no aumenta, lo que sugiere que el modelo generalizó correctamente la estructura principal de los datos. Este comportamiento es común en modelos de alta capacidad como XGBoost cuando se entrenan con muchas iteraciones, incluso usando regularización (<code class="docutils literal notranslate"><span class="pre">reg_alpha=5.0,</span> <span class="pre">reg_lambda=5.0,</span> <span class="pre">subsample</span></code>) y submuestreo, y refleja que parte del sobreajuste se debe a memorizar detalles específicos del conjunto de entrenamiento sin afectar la generalización.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5. Evaluación en Test</span>

<span class="n">probs_test</span> <span class="o">=</span> <span class="n">bst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>
<span class="n">preds_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">labels_bin_test</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">))</span>

<span class="n">metrics_test</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">),</span>
    <span class="s1">&#39;f1_weighted&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
    <span class="s1">&#39;f1_macro&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">),</span>
    <span class="s1">&#39;precision_weighted&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
    <span class="s1">&#39;recall_weighted&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">),</span>
    <span class="s1">&#39;roc_auc_macro&#39;</span><span class="p">:</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">labels_bin_test</span><span class="p">,</span> <span class="n">probs_test</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Resultados Finales en el Test Set ---&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics_test</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Resultados Finales en el Test Set ---
accuracy: 0.7382
f1_weighted: 0.7362
f1_macro: 0.7303
precision_weighted: 0.7470
recall_weighted: 0.7382
roc_auc_macro: 0.9705
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>TF-IDF + XGBoost</strong>, entrenado con aceleración GPU y detenido por early stopping en la época 3863, fue evaluado sobre el conjunto de <strong>prueba</strong>, el cual mantiene la distribución original y desbalanceada de clases.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Métrica</strong></p></th>
<th class="head"><p><strong>Valor</strong></p></th>
<th class="head"><p><strong>Observación Técnica</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Accuracy (Exactitud)</p></td>
<td><p>73.82 %</p></td>
<td><p>Proporción de predicciones correctas; rendimiento competitivo para alta dimensionalidad.</p></td>
</tr>
<tr class="row-odd"><td><p>F1-Score Weighted</p></td>
<td><p>73.62 %</p></td>
<td><p>Métrica principal: refleja equilibrio entre precisión y recall considerando el desbalance.</p></td>
</tr>
<tr class="row-even"><td><p>F1-Score Macro</p></td>
<td><p>73.03 %</p></td>
<td><p>Buen rendimiento promedio por clase, incluyendo las minoritarias.</p></td>
</tr>
<tr class="row-odd"><td><p>Precision Weighted</p></td>
<td><p>74.70 %</p></td>
<td><p>Alta fiabilidad en las predicciones positivas, evitando falsos positivos.</p></td>
</tr>
<tr class="row-even"><td><p>Recall Weighted</p></td>
<td><p>73.82 %</p></td>
<td><p>Capacidad consistente para detectar instancias positivas.</p></td>
</tr>
<tr class="row-odd"><td><p>ROC AUC Macro</p></td>
<td><p>97.05 %</p></td>
<td><p>Excelente capacidad discriminativa entre las 24 clases, indicando separabilidad probabilística.</p></td>
</tr>
</tbody>
</table>
</div>
<p>El modelo demuestra una <strong>generalización sólida</strong>, con métricas de test consistentes con la validación y un <strong>sobreajuste leve (gap Train-Val ~6-7%)</strong> que no compromete su desempeño.</p>
<ul class="simple">
<li><p><strong>Balance y robustez:</strong> La proximidad entre <strong>F1 Weighted (73.62%)</strong> y <strong>F1 Macro (73.03%)</strong> indica que el modelo mantiene un rendimiento uniforme entre clases mayoritarias y minoritarias.</p></li>
<li><p><strong>Capacidad discriminativa:</strong> El <strong>ROC-AUC Macro (97.05%)</strong> evidencia que las probabilidades generadas por XGBoost separan efectivamente las clases, lo que es útil para tareas de ranking o priorización.</p></li>
<li><p><strong>Fiabilidad y estabilidad:</strong> Las métricas reflejan que la combinación de TF-IDF con XGBoost maneja bien la alta dimensionalidad del texto y generaliza correctamente a datos no vistos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">Y_test</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">preds_test</span>

<span class="n">mostrar_matriz_confusion</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">category_map</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Matriz de Confusión - XGBoost</span><span class="se">\n</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="n">metrics_test</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c06356b3a8c33142aa01432d665fb73b24585f41a2a88398ebd7092398e2686b.png" src="_images/c06356b3a8c33142aa01432d665fb73b24585f41a2a88398ebd7092398e2686b.png" />
</div>
</div>
<p>La <strong>Matriz de Confusión</strong> del modelo <strong>TF-IDF + XGBoost</strong>, con una precisión general del <strong>73.82%</strong>, ofrece una visión detallada del rendimiento por clase. El modelo clasifica correctamente la mayoría de los puestos de trabajo, mostrando gran efectividad en dominios claramente diferenciados. Las confusiones más frecuentes ocurren entre clases con vocabularios semánticamente cercanos, indicando que el modelo tiene dificultades para separar matices entre categorías altamente relacionadas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_curvas_roc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="n">y_prob</span><span class="o">=</span><span class="n">probs_test</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="s2">&quot;Curvas ROC–AUC por clase - XGBoost&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/30d287e7dacbabbddbc7c7631ac80c4608478aa9babed4947422ad0c20fa6088.png" src="_images/30d287e7dacbabbddbc7c7631ac80c4608478aa9babed4947422ad0c20fa6088.png" />
</div>
</div>
<p>Las <strong>curvas ROC-AUC por clase</strong> del modelo <strong>XGBoost</strong> confirman una <strong>capacidad discriminativa alta y consistente</strong> en clasificación multiclase. Con valores de AUC entre <strong>0.87 y 1.00</strong>, el modelo logra separar correctamente las clases en términos probabilísticos, incluso en aquellas con menor precisión en la matriz de confusión. Esto indica que el modelo asigna <strong>probabilidades bien calibradas</strong>, permitiendo distinguir entre clases con alta <strong>sensibilidad</strong> y <strong>especificidad</strong>.</p>
<section id="id2">
<h3>Análisis de errores<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analizar_errores</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds_test</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Clase </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">)},</span>
    <span class="n">nombre_modelo</span><span class="o">=</span><span class="s2">&quot;XGBoost&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
 RESUMEN DE ERRORES - XGBoost
============================================================
 Predicciones correctas: 296
 Predicciones incorrectas: 105
 Total de ejemplos: 401
 Accuracy: 73.82%
 Tasa de error: 26.18%
============================================================

 ERRORES POR CLASE:
------------------------------------------------------------
Clase 0                  : 2/18 errores (88.89% accuracy)
Clase 1                  : 4/18 errores (77.78% accuracy)
Clase 2                  : 9/15 errores (40.00% accuracy)
Clase 3                  : 8/15 errores (46.67% accuracy)
Clase 4                  : 7/15 errores (53.33% accuracy)
Clase 5                  : 1/15 errores (93.33% accuracy)
Clase 6                  : 4/18 errores (77.78% accuracy)
Clase 7                  : 7/17 errores (58.82% accuracy)
Clase 8                  : 6/15 errores (60.00% accuracy)
Clase 9                  : 3/18 errores (83.33% accuracy)
Clase 10                 : 4/18 errores (77.78% accuracy)
Clase 11                 : 1/17 errores (94.12% accuracy)
Clase 12                 : 4/17 errores (76.47% accuracy)
Clase 13                 : 2/16 errores (87.50% accuracy)
Clase 14                 : 8/14 errores (42.86% accuracy)
Clase 15                 : 3/18 errores (83.33% accuracy)
Clase 16                 : 7/18 errores (61.11% accuracy)
Clase 17                 : 3/18 errores (83.33% accuracy)
Clase 18                 : 5/17 errores (70.59% accuracy)
Clase 19                 : 2/17 errores (88.24% accuracy)
Clase 20                 : 2/18 errores (88.89% accuracy)
Clase 21                 : 4/17 errores (76.47% accuracy)
Clase 22                 : 7/17 errores (58.82% accuracy)
Clase 23                 : 2/15 errores (86.67% accuracy)

 CONFUSIONES MÁS COMUNES:
------------------------------------------------------------
Clase 16 → Clase 0: 4 veces (3.8% de errores)
Clase 4 → Clase 23: 3 veces (2.9% de errores)
Clase 14 → Clase 4: 3 veces (2.9% de errores)
Clase 3 → Clase 2: 3 veces (2.9% de errores)
Clase 18 → Clase 1: 3 veces (2.9% de errores)
Clase 7 → Clase 16: 3 veces (2.9% de errores)
Clase 21 → Clase 19: 2 veces (1.9% de errores)
Clase 1 → Clase 18: 2 veces (1.9% de errores)
Clase 2 → Clase 23: 2 veces (1.9% de errores)
Clase 6 → Clase 15: 2 veces (1.9% de errores)
</pre></div>
</div>
</div>
</div>
<p>A pesar de la sólida <strong>Accuracy global del 73.82%</strong>, el análisis detallado revela una heterogeneidad significativa en el rendimiento por clase. Las clases <strong>2 (40.00%)</strong>, <strong>14 (42.86%)</strong>, <strong>3 (46.67%)</strong> y <strong>4 (53.33%)</strong> se identifican como los puntos débiles del modelo, concentrando la mayor proporción de errores, en contraste con la clasificación casi perfecta de otras clases, como la <strong>Clase 11 (94.12%)</strong>.</p>
<p>Los patrones de confusión más frecuentes destacan la fuerte tendencia del modelo a confundir la <strong>Clase 16 con la Clase 0</strong> (el error más común, 3.8% del total), así como confusiones recurrentes entre otras clases problemáticas (<strong>Clase 3 → Clase 2</strong>, <strong>Clase 14 → Clase 4</strong>). Estos ejemplos sugieren que el vocabulario TF-IDF no es suficientemente distintivo o que el desbalance de clases afecta el entrenamiento, requiriendo estrategias específicas para mejorar el rendimiento en estas categorías.</p>
</section>
</section>
<section id="modelo-5-fasttext">
<h2>Modelo 5: FastText<a class="headerlink" href="#modelo-5-fasttext" title="Permalink to this heading">#</a></h2>
<p>El sistema utiliza la librería <strong>FastText</strong> para la clasificación de texto, un modelo conocido por su alta eficiencia y rendimiento, combinando la velocidad de una red <em>feed-forward</em> con la riqueza semántica de los <em>embeddings</em> de subpalabras (<em>n-gramas</em> de caracteres). Esta implementación incorpora vectores de palabras <strong>pre-entrenados (cc.en.300.vec)</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">fasttext</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">fasttext.util</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CONFIGURACIÓN  </span>
<span class="n">RESULTS_DIR</span> <span class="o">=</span> <span class="s1">&#39;results_fasttext&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>El modelo se entrena en modo supervisado utilizando <strong>FastText</strong> (<code class="docutils literal notranslate"><span class="pre">fasttext.train_supervised</span></code>), aprovechando <strong>embeddings preentrenados</strong> para acelerar la convergencia y mejorar la calidad de las representaciones semánticas. Se emplea el archivo <code class="docutils literal notranslate"><span class="pre">pretrainedVectors='modelos/cc.en.300.vec'</span></code>, inicializando los vectores de palabras con <strong>300 dimensiones</strong>, lo que permite que el modelo comience con un conocimiento semántico sólido mediante <strong>Transfer Learning</strong>.</p>
<p>La configuración del modelo incluye una <strong>dimensión de embeddings de 300</strong> (<code class="docutils literal notranslate"><span class="pre">dim=300</span></code>), <strong>función de pérdida Softmax</strong> (<code class="docutils literal notranslate"><span class="pre">loss='softmax'</span></code>) para clasificación multiclase, <strong>25 épocas</strong> de entrenamiento (<code class="docutils literal notranslate"><span class="pre">epoch=25</span></code>) y una <strong>tasa de aprendizaje alta</strong> (<code class="docutils literal notranslate"><span class="pre">lr=0.5</span></code>) para favorecer la convergencia rápida.</p>
<p>Para la representación del texto, se utilizan <strong>bigramas de palabras</strong> (<code class="docutils literal notranslate"><span class="pre">wordNgrams=2</span></code>) que capturan el contexto local, mientras que los <em>n-gramas</em> de caracteres se desactivan (<code class="docutils literal notranslate"><span class="pre">minn=0</span></code>, <code class="docutils literal notranslate"><span class="pre">maxn=0</span></code>) confiando únicamente en los embeddings de palabras completas y sus n-gramas de palabras, lo cual es apropiado al usar vectores preentrenados de alta calidad.</p>
<p>El entrenamiento se realiza sobre un <strong>corpus etiquetado</strong> en formato <code class="docutils literal notranslate"><span class="pre">.txt</span></code>, donde cada línea contiene una etiqueta y un texto. Esta configuración permite obtener un clasificador multiclase eficiente, con representaciones semánticas sólidas y capacidad de capturar relaciones contextuales locales entre palabras.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Entrenar clasificador con embeddings pre-entrenados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ENTRENAMIENTO DEL MODELO&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">fasttext</span><span class="o">.</span><span class="n">train_supervised</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="s1">&#39;processed_data/fasttext_train.txt&#39;</span><span class="p">,</span>
    
    <span class="n">pretrainedVectors</span><span class="o">=</span><span class="s1">&#39;/home/sara/modelos/cc.en.300.vec/cc.en.300.vec&#39;</span><span class="p">,</span>
    
    <span class="n">dim</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>              
    <span class="n">epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">wordNgrams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>         
    
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span>
    <span class="n">minCount</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>          
    
    <span class="n">bucket</span><span class="o">=</span><span class="mi">2000000</span><span class="p">,</span>
    <span class="n">minn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>               
    <span class="n">maxn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>               
    
    <span class="n">thread</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Entrenamiento completado en </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> segundos!&quot;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RESULTS_DIR</span><span class="p">,</span> <span class="s1">&#39;fasttext_model_pretrained.bin&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Modelo guardado: </span><span class="si">{</span><span class="n">RESULTS_DIR</span><span class="si">}</span><span class="s2">/fasttext_model_pretrained.bin&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
ENTRENAMIENTO DEL MODELO
======================================================================
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Read 1M words
Number of words:  39142
Number of labels: 24
Progress:  99.0% words/sec/thread: 1782576 lr:  0.004948 avg.loss:  0.221382 ETA:   0h 0m 0s 38.0% words/sec/thread: 1392684 lr:  0.310102 avg.loss:  0.566606 ETA:   0h 0m 8s words/sec/thread: 1447277 lr:  0.284387 avg.loss:  0.497748 ETA:   0h 0m 7s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Entrenamiento completado en 111.26 segundos!
 Modelo guardado: results_fasttext/fasttext_model_pretrained.bin
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Progress: 100.0% words/sec/thread: 1784194 lr:  0.000000 avg.loss:  0.219314 ETA:   0h 0m 0s
</pre></div>
</div>
</div>
</div>
<p>Se evalúa el modelo sobre el conjunto de validación utilizando el método test() de FastText, que calcula precisión y recall directamente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2. Evaluación en Validación</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; EVALUACIÓN EN VALIDACIÓN&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">n_val</span><span class="p">,</span> <span class="n">precision_val</span><span class="p">,</span> <span class="n">recall_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">&#39;processed_data/fasttext_val.txt&#39;</span><span class="p">)</span>
<span class="n">f1_val</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precision_val</span> <span class="o">*</span> <span class="n">recall_val</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision_val</span> <span class="o">+</span> <span class="n">recall_val</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">precision_val</span> <span class="o">+</span> <span class="n">recall_val</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Samples: </span><span class="si">{</span><span class="n">n_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recall: </span><span class="si">{</span><span class="n">recall_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1-Score: </span><span class="si">{</span><span class="n">f1_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
 EVALUACIÓN EN VALIDACIÓN
======================================================================
Samples: 401
Precision: 0.7057
Recall: 0.7057
F1-Score: 0.7057
</pre></div>
</div>
</div>
</div>
<p>El análisis de las métricas de evaluación en el conjunto de validación del modelo indica un rendimiento <strong>sólido y equilibrado</strong> con un <strong>F1-Score de 0.7057</strong>. La coincidencia de los valores de Precisión, <em>Recall</em> y F1-Score sugiere una distribución uniforme de errores bajo el umbral de clasificación estándar de la librería. Este resultado inicial, si bien es robusto y producto de la transferencia de conocimiento semántico aportado por los <em>embeddings</em> preentrenados de 300 dimensiones, se sitúa ligeramente <strong>por debajo</strong> del F1-Score máximo alcanzado por la arquitectura <strong>Bi-LSTM</strong>, lo que requiere una evaluación exhaustiva en el conjunto de prueba para determinar la capacidad de generalización comparativa de ambos modelos.</p>
<p>Para obtener una evaluación más completa, se realiza una predicción manual y robusta sobre el conjunto de <em>Test</em>.</p>
<ul class="simple">
<li><p><strong>Manejo de Datos:</strong> El archivo de <em>Test</em> se carga de forma manual para separar el texto y las etiquetas <em>string</em> originales (<code class="docutils literal notranslate"><span class="pre">__label__X</span></code>). Las etiquetas se mapean a índices numéricos para la compatibilidad con las librerías de métricas de Python (ej., <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>).</p></li>
<li><p><strong>Predicción Robusta:</strong> Se realiza un bucle de predicción por muestra (<code class="docutils literal notranslate"><span class="pre">model.predict(text,</span> <span class="pre">k=num_classes,</span> <span class="pre">threshold=0.0)</span></code>):</p>
<ul>
<li><p>Se solicita a FastText que devuelva las probabilidades para <strong>todas las clases</strong> (<code class="docutils literal notranslate"><span class="pre">k=num_classes</span></code>, <span class="math notranslate nohighlight">\(\text{threshold}=0.0\)</span>).</p></li>
<li><p>Esto es esencial para construir el vector de probabilidades (<code class="docutils literal notranslate"><span class="pre">probs_test_all</span></code>), necesario para el cálculo preciso de métricas avanzadas como el <strong>ROC-AUC (macro)</strong>.</p></li>
<li><p>Se implementa un manejo de errores (try/except) y un <em>fallback</em> para asegurar que el proceso no se interrumpa ante datos inválidos y que la salida tenga el formato correcto para las métricas.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Cargar datos de test</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Cargando datos de test...&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_fasttext_file</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Carga archivo FastText manteniendo etiquetas como strings&quot;&quot;&quot;</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;__label__&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>  
                <span class="n">text</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
                <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">texts</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="n">test_texts</span><span class="p">,</span> <span class="n">Y_test_str</span> <span class="o">=</span> <span class="n">load_fasttext_file</span><span class="p">(</span><span class="s1">&#39;processed_data/fasttext_test.txt&#39;</span><span class="p">)</span>

<span class="c1"># Obtener todas las etiquetas únicas</span>
<span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Y_test_str</span><span class="p">))</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span>

<span class="c1"># Crear mapeo de etiquetas</span>
<span class="n">label_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)}</span>
<span class="n">idx_to_label</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">label</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">label_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># Convertir etiquetas a índices numéricos para métricas</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">label_to_idx</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">Y_test_str</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Cargando datos de test...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Predicciones en Test (VERSIÓN ROBUSTA)</span>
<span class="n">preds_test_str</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">preds_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">probs_test_all</span> <span class="o">=</span> <span class="p">[]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Prediciendo en </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> muestras de test...&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_texts</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Procesados </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_texts</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)...&quot;</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Método seguro: usar threshold para obtener todas las clases</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        
        <span class="c1"># Extraer labels y probs</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">labels_pred</span><span class="p">,</span> <span class="n">probs_pred</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">labels_pred</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">probs_pred</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[]</span>
        
        <span class="c1"># Asegurar que son listas</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels_pred</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">probs_pred</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="n">probs_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">probs_pred</span><span class="p">]</span>
        
        <span class="c1"># Convertir probs a lista si es necesario</span>
        <span class="n">probs_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">probs_pred</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">probs_pred</span><span class="p">,</span> <span class="s1">&#39;__iter__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">probs_pred</span><span class="p">]</span>
        
        <span class="c1"># Tomar top prediction</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">top_label_str</span> <span class="o">=</span> <span class="n">labels_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;__label__&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">preds_test_str</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">top_label_str</span><span class="p">)</span>
            <span class="n">top_label_idx</span> <span class="o">=</span> <span class="n">label_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">top_label_str</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">preds_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">top_label_idx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback si no hay predicciones</span>
            <span class="n">preds_test_str</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">preds_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Crear vector de probabilidades</span>
        <span class="n">prob_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">probs_list</span><span class="p">):</span>
            <span class="n">label_str</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;__label__&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">label_str</span> <span class="ow">in</span> <span class="n">label_to_idx</span><span class="p">:</span>
                <span class="n">class_idx</span> <span class="o">=</span> <span class="n">label_to_idx</span><span class="p">[</span><span class="n">label_str</span><span class="p">]</span>
                <span class="n">prob_vector</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
        
        <span class="n">probs_test_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prob_vector</span><span class="p">)</span>
        
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Error en muestra </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Añadir predicción por defecto</span>
        <span class="n">preds_test_str</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">preds_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">probs_test_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>

<span class="n">preds_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preds_test</span><span class="p">)</span>
<span class="n">probs_test_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">probs_test_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    Predicciones completadas&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>📊 Prediciendo en 401 muestras de test...
   ✅ Predicciones completadas
</pre></div>
</div>
</div>
</div>
<p>Se utiliza el vector de etiquetas reales (<code class="docutils literal notranslate"><span class="pre">Y_test</span></code>) y las predicciones (<code class="docutils literal notranslate"><span class="pre">preds_test</span></code>, <code class="docutils literal notranslate"><span class="pre">probs_test_all</span></code>) para calcular el rendimiento final.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; MÉTRICAS DE PERFORMANCE EN TEST&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">),</span>
    <span class="s1">&#39;Precision (weighted)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Precision (macro)&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (weighted)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;Recall (macro)&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (weighted)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;F1-Score (macro)&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
<span class="p">}</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">Y_test_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">num_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">probs_test_all</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Y_test_bin</span><span class="p">,</span> <span class="n">probs_test_all</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;ROC-AUC (macro)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_auc</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No se pudo calcular ROC-AUC: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;ROC-AUC (macro)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Métricas:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">30s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>======================================================================
 MÉTRICAS DE PERFORMANCE EN TEST
======================================================================

 Métricas:
Accuracy                      : 0.6833
Precision (weighted)          : 0.6947
Precision (macro)             : 0.6948
Recall (weighted)             : 0.6833
Recall (macro)                : 0.6837
F1-Score (weighted)           : 0.6823
F1-Score (macro)              : 0.6827
ROC-AUC (macro)               : 0.9572
</pre></div>
</div>
</div>
</div>
<p>El modelo <strong>FastText</strong> exhibió un rendimiento de generalización <strong>inferior</strong> en comparación con el modelo <strong>Bi-LSTM</strong> y es, a la postre, el <strong>peor clasificador</strong> entre los cinco modelos evaluados en el proyecto. Específicamente, el <strong>F1-Score ponderado de 0.6823</strong> y la <strong>Accuracy de 0.6833</strong> son modestos, confirmando la brecha de rendimiento frente a arquitecturas más complejas. No obstante, FastText demostró una fortaleza inherente al lograr un rendimiento <strong>equilibrado</strong> entre clases, evidenciado por la mínima diferencia entre las métricas <em>weighted</em> y <em>macro</em>. Su alta capacidad de discriminación, reflejada en un <strong>ROC-AUC (macro) de 0.9572</strong>, confirma que el problema no radica en distinguir probabilidades, sino en optimizar la predicción final de categorías, lo cual lo consolida como un clasificador eficiente pero de <strong>baja efectividad</strong> para este problema en particular.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">preds_test</span><span class="p">)</span>

<span class="n">mostrar_matriz_confusion</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds_test</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">idx_to_label</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Matriz de Confusión - FastText (Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%)&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/781c3dbc95fbfabb411c10ac0371f7cb0ebcec383e0f8e4c84a84db30858b195.png" src="_images/781c3dbc95fbfabb411c10ac0371f7cb0ebcec383e0f8e4c84a84db30858b195.png" />
</div>
</div>
<p>El modelo FastText alcanzó una <strong>precisión (Accuracy) del 68.33%</strong>, lo que sugiere que es un clasificador funcional, aunque con un margen considerable de mejora. La <strong>matriz de confusión</strong> ilustra que el modelo logra una clasificación correcta en la mayoría de las instancias, lo cual está representado por los valores altos a lo largo de la <strong>diagonal principal</strong>. Sin embargo, la presencia de números significativos <strong>fuera de esta diagonal</strong> indica que el modelo frecuentemente confunde distintas categorías, lo que resulta en una tasa de error moderada.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mostrar_curvas_roc</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="n">y_prob</span><span class="o">=</span><span class="n">probs_test_all</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">titulo</span><span class="o">=</span><span class="s1">&#39;Curvas ROC por Clase - FastText con Embeddings Pre-entrenados&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c7e5f12634dbc58787f78d315d610662f5bccb36072dad566d2ab4415f2ed92f.png" src="_images/c7e5f12634dbc58787f78d315d610662f5bccb36072dad566d2ab4415f2ed92f.png" />
</div>
</div>
<p>El modelo FastText mostró una <strong>Precisión global del 68.33%</strong>, limitada por la confusión entre categorías temáticamente similares, como se observa en la matriz. A pesar de esto, las <strong>Curvas ROC</strong> revelaron un <strong>rendimiento individual por clase</strong> notablemente superior: la gran mayoría de las clases alcanzaron un <strong>AUC superior a 0.95</strong>, indicando una fuerte capacidad de discriminación positiva. Este contraste sugiere que el modelo es robusto para la mayoría de las categorías, y su precisión general se ve afectada principalmente fallos específicos en las fronteras de ciertas clases problemáticas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">analizar_errores</span><span class="p">(</span>
    <span class="n">y_true</span><span class="o">=</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">preds_test</span><span class="p">,</span>
    <span class="n">category_map</span><span class="o">=</span><span class="n">idx_to_label</span><span class="p">,</span>
    <span class="n">nombre_modelo</span><span class="o">=</span><span class="s1">&#39;FastText con Embeddings Pre-entrenados&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
 RESUMEN DE ERRORES - FastText con Embeddings Pre-entrenados
============================================================
 Predicciones correctas: 270
 Predicciones incorrectas: 131
 Total de ejemplos: 401
 Accuracy: 67.33%
 Tasa de error: 32.67%
============================================================

 ERRORES POR CLASE:
------------------------------------------------------------
ACCOUNTANT               : 2/18 errores (88.89% accuracy)
ADVOCATE                 : 9/18 errores (50.00% accuracy)
AGRICULTURE              : 3/15 errores (80.00% accuracy)
APPAREL                  : 6/15 errores (60.00% accuracy)
ARTS                     : 7/15 errores (53.33% accuracy)
AUTOMOBILE               : 1/15 errores (93.33% accuracy)
AVIATION                 : 7/18 errores (61.11% accuracy)
BANKING                  : 7/17 errores (58.82% accuracy)
BPO                      : 0/15 errores (100.00% accuracy)
BUSINESS-DEVELOPMENT     : 6/18 errores (66.67% accuracy)
CHEF                     : 6/18 errores (66.67% accuracy)
CONSTRUCTION             : 2/17 errores (88.24% accuracy)
CONSULTANT               : 8/17 errores (52.94% accuracy)
DESIGNER                 : 7/16 errores (56.25% accuracy)
DIGITAL-MEDIA            : 8/14 errores (42.86% accuracy)
ENGINEERING              : 5/18 errores (72.22% accuracy)
FINANCE                  : 7/18 errores (61.11% accuracy)
FITNESS                  : 9/18 errores (50.00% accuracy)
HEALTHCARE               : 8/17 errores (52.94% accuracy)
HR                       : 2/17 errores (88.24% accuracy)
INFORMATION-TECHNOLOGY   : 3/18 errores (83.33% accuracy)
PUBLIC-RELATIONS         : 6/17 errores (64.71% accuracy)
SALES                    : 9/17 errores (47.06% accuracy)
TEACHER                  : 3/15 errores (80.00% accuracy)

 CONFUSIONES MÁS COMUNES:
------------------------------------------------------------
FITNESS → ADVOCATE: 5 veces (3.8% de errores)
ADVOCATE → HEALTHCARE: 4 veces (3.1% de errores)
AVIATION → ENGINEERING: 3 veces (2.3% de errores)
HEALTHCARE → ADVOCATE: 3 veces (2.3% de errores)
DIGITAL-MEDIA → PUBLIC-RELATIONS: 3 veces (2.3% de errores)
SALES → APPAREL: 2 veces (1.5% de errores)
ARTS → TEACHER: 2 veces (1.5% de errores)
CONSULTANT → HEALTHCARE: 2 veces (1.5% de errores)
PUBLIC-RELATIONS → HR: 2 veces (1.5% de errores)
BUSINESS-DEVELOPMENT → BANKING: 2 veces (1.5% de errores)
</pre></div>
</div>
</div>
</div>
<p>El resumen de errores confirma la <strong>precisión general del 67.33%</strong> del modelo FastText, la cual está marcada por una variabilidad extrema en el rendimiento entre categorías. El modelo es <strong>altamente fiable</strong> en clases como <strong>BPO (100% de precisión)</strong> y <strong>AUTOMOBILE (93.33%)</strong>, pero presenta un desempeño críticamente bajo en <strong>DIGITAL-MEDIA (42.86%)</strong> y <strong>SALES (47.06%)</strong>, junto con otros roles como <strong>ADVOCATE</strong> y <strong>FITNESS</strong> que apenas superan el 50%. Las <strong>confusiones más comunes</strong> detalladas—particularmente <strong>FITNESS → ADVOCATE</strong> y el intercambio entre <strong>ADVOCATE ↔ HEALTHCARE</strong>—validan que la principal debilidad del modelo reside en su incapacidad para discriminar consistentemente entre clases con similitud conceptual, lo que explica la alta tasa de error general pese al buen rendimiento en categorías específicas.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="eda.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Análisis exploratorio de Datos</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="comparaciones.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Comparaciones y Conclusiones</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion">Métricas de Evaluación</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proceso-documentado">Proceso Documentado</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-1-distilbert">Modelo 1: DistilBERT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-rendimiento-en-el-conjunto-de-prueba">Métricas de rendimiento en el conjunto de prueba</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-de-errores">Análisis de errores</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-2-word2vec-bilstm">Modelo 2: Word2Vec + BiLSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-3-cnn-1d-para-texto-con-embeddings-preentrenados">Modelo 3: CNN-1D para texto (con embeddings preentrenados)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Métricas de rendimiento en el conjunto de prueba</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-4-tf-idf-xgboost-gpu-version">Modelo 4: TF-IDF + XGBoost (GPU version)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Análisis de errores</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-5-fasttext">Modelo 5: FastText</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>